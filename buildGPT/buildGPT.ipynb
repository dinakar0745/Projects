{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a680930c",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2803617075.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[2], line 2\u001b[1;36m\u001b[0m\n\u001b[1;33m    git clone https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\u001b[0m\n\u001b[1;37m        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# We always start with a dataset to train on. Let's download the tiny shakespeare dataset\n",
    "git clone https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b665fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read it in to inspect it\n",
    "with open('input.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13d858c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of dataset:  1115393\n"
     ]
    }
   ],
   "source": [
    "print(\"Length of dataset: \", len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a605e1eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you know Caius Marcius is chief enemy to the people.\n",
      "\n",
      "All:\n",
      "We know't, we know't.\n",
      "\n",
      "First Citizen:\n",
      "Let us kill him, and we'll have corn at our own price.\n",
      "Is't a verdict?\n",
      "\n",
      "All:\n",
      "No more talking on't; let it be done: away, away!\n",
      "\n",
      "Second Citizen:\n",
      "One word, good citizens.\n",
      "\n",
      "First Citizen:\n",
      "We are accounted poor citizens, the patricians good.\n",
      "What authority surfeits on would relieve us: if they\n",
      "would yield us but the superfluity, while it were\n",
      "wholesome, we might guess they relieved us humanely;\n",
      "but they think we are too dear: the leanness that\n",
      "afflicts us, the object of our misery, is as an\n",
      "inventory to particularise their abundance; our\n",
      "sufferance is a gain to them Let us revenge this with\n",
      "our pikes, ere we become rakes: for the gods know I\n",
      "speak this in hunger for bread, not in thirst for revenge.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(text[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fdac08c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n",
      "65\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "vocob_size = len(chars)\n",
    "print(''.join(chars))\n",
    "print(vocob_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b994cd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[46, 47, 47, 1, 58, 46, 43, 56, 43]\n",
      "hii there\n"
     ]
    }
   ],
   "source": [
    "# create a mapping from characters to integers\n",
    "stoi = { ch:i for i,ch in enumerate(chars) }\n",
    "itos = { i:ch for i,ch in enumerate(chars) }\n",
    "encode = lambda s: [stoi[c] for c in s] # encoder: take a string, output a list of integers\n",
    "decode = lambda l: ''.join([itos[i] for i in l]) # decoder: take a list of integers, output a string\n",
    "\n",
    "print(encode(\"hii there\"))\n",
    "print(decode(encode(\"hii there\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "88e50002",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda activate dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c6db2b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torch in c:\\users\\dinak\\appdata\\roaming\\python\\python311\\site-packages (2.2.0)\n",
      "Requirement already satisfied: filelock in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\dinak\\appdata\\roaming\\python\\python311\\site-packages (from torch) (4.9.0)\n",
      "Requirement already satisfied: sympy in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (1.11.1)\n",
      "Requirement already satisfied: networkx in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (2023.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\programdata\\anaconda3\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e74120b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1115393]) torch.int64\n",
      "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
      "         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,\n",
      "        57, 54, 43, 39, 49,  8,  0,  0, 13, 50, 50, 10,  0, 31, 54, 43, 39, 49,\n",
      "         6,  1, 57, 54, 43, 39, 49,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47,\n",
      "        58, 47, 64, 43, 52, 10,  0, 37, 53, 59,  1, 39, 56, 43,  1, 39, 50, 50,\n",
      "         1, 56, 43, 57, 53, 50, 60, 43, 42,  1, 56, 39, 58, 46, 43, 56,  1, 58,\n",
      "        53,  1, 42, 47, 43,  1, 58, 46, 39, 52,  1, 58, 53,  1, 44, 39, 51, 47,\n",
      "        57, 46, 12,  0,  0, 13, 50, 50, 10,  0, 30, 43, 57, 53, 50, 60, 43, 42,\n",
      "         8,  1, 56, 43, 57, 53, 50, 60, 43, 42,  8,  0,  0, 18, 47, 56, 57, 58,\n",
      "         1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 18, 47, 56, 57, 58,  6,  1, 63,\n",
      "        53, 59,  1, 49, 52, 53, 61,  1, 15, 39, 47, 59, 57,  1, 25, 39, 56, 41,\n",
      "        47, 59, 57,  1, 47, 57,  1, 41, 46, 47, 43, 44,  1, 43, 52, 43, 51, 63,\n",
      "         1, 58, 53,  1, 58, 46, 43,  1, 54, 43, 53, 54, 50, 43,  8,  0,  0, 13,\n",
      "        50, 50, 10,  0, 35, 43,  1, 49, 52, 53, 61,  5, 58,  6,  1, 61, 43,  1,\n",
      "        49, 52, 53, 61,  5, 58,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47, 58,\n",
      "        47, 64, 43, 52, 10,  0, 24, 43, 58,  1, 59, 57,  1, 49, 47, 50, 50,  1,\n",
      "        46, 47, 51,  6,  1, 39, 52, 42,  1, 61, 43,  5, 50, 50,  1, 46, 39, 60,\n",
      "        43,  1, 41, 53, 56, 52,  1, 39, 58,  1, 53, 59, 56,  1, 53, 61, 52,  1,\n",
      "        54, 56, 47, 41, 43,  8,  0, 21, 57,  5, 58,  1, 39,  1, 60, 43, 56, 42,\n",
      "        47, 41, 58, 12,  0,  0, 13, 50, 50, 10,  0, 26, 53,  1, 51, 53, 56, 43,\n",
      "         1, 58, 39, 50, 49, 47, 52, 45,  1, 53, 52,  5, 58, 11,  1, 50, 43, 58,\n",
      "         1, 47, 58,  1, 40, 43,  1, 42, 53, 52, 43, 10,  1, 39, 61, 39, 63,  6,\n",
      "         1, 39, 61, 39, 63,  2,  0,  0, 31, 43, 41, 53, 52, 42,  1, 15, 47, 58,\n",
      "        47, 64, 43, 52, 10,  0, 27, 52, 43,  1, 61, 53, 56, 42,  6,  1, 45, 53,\n",
      "        53, 42,  1, 41, 47, 58, 47, 64, 43, 52, 57,  8,  0,  0, 18, 47, 56, 57,\n",
      "        58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 35, 43,  1, 39, 56, 43,  1,\n",
      "        39, 41, 41, 53, 59, 52, 58, 43, 42,  1, 54, 53, 53, 56,  1, 41, 47, 58,\n",
      "        47, 64, 43, 52, 57,  6,  1, 58, 46, 43,  1, 54, 39, 58, 56, 47, 41, 47,\n",
      "        39, 52, 57,  1, 45, 53, 53, 42,  8,  0, 35, 46, 39, 58,  1, 39, 59, 58,\n",
      "        46, 53, 56, 47, 58, 63,  1, 57, 59, 56, 44, 43, 47, 58, 57,  1, 53, 52,\n",
      "         1, 61, 53, 59, 50, 42,  1, 56, 43, 50, 47, 43, 60, 43,  1, 59, 57, 10,\n",
      "         1, 47, 44,  1, 58, 46, 43, 63,  0, 61, 53, 59, 50, 42,  1, 63, 47, 43,\n",
      "        50, 42,  1, 59, 57,  1, 40, 59, 58,  1, 58, 46, 43,  1, 57, 59, 54, 43,\n",
      "        56, 44, 50, 59, 47, 58, 63,  6,  1, 61, 46, 47, 50, 43,  1, 47, 58,  1,\n",
      "        61, 43, 56, 43,  0, 61, 46, 53, 50, 43, 57, 53, 51, 43,  6,  1, 61, 43,\n",
      "         1, 51, 47, 45, 46, 58,  1, 45, 59, 43, 57, 57,  1, 58, 46, 43, 63,  1,\n",
      "        56, 43, 50, 47, 43, 60, 43, 42,  1, 59, 57,  1, 46, 59, 51, 39, 52, 43,\n",
      "        50, 63, 11,  0, 40, 59, 58,  1, 58, 46, 43, 63,  1, 58, 46, 47, 52, 49,\n",
      "         1, 61, 43,  1, 39, 56, 43,  1, 58, 53, 53,  1, 42, 43, 39, 56, 10,  1,\n",
      "        58, 46, 43,  1, 50, 43, 39, 52, 52, 43, 57, 57,  1, 58, 46, 39, 58,  0,\n",
      "        39, 44, 44, 50, 47, 41, 58, 57,  1, 59, 57,  6,  1, 58, 46, 43,  1, 53,\n",
      "        40, 48, 43, 41, 58,  1, 53, 44,  1, 53, 59, 56,  1, 51, 47, 57, 43, 56,\n",
      "        63,  6,  1, 47, 57,  1, 39, 57,  1, 39, 52,  0, 47, 52, 60, 43, 52, 58,\n",
      "        53, 56, 63,  1, 58, 53,  1, 54, 39, 56, 58, 47, 41, 59, 50, 39, 56, 47,\n",
      "        57, 43,  1, 58, 46, 43, 47, 56,  1, 39, 40, 59, 52, 42, 39, 52, 41, 43,\n",
      "        11,  1, 53, 59, 56,  0, 57, 59, 44, 44, 43, 56, 39, 52, 41, 43,  1, 47,\n",
      "        57,  1, 39,  1, 45, 39, 47, 52,  1, 58, 53,  1, 58, 46, 43, 51,  1, 24,\n",
      "        43, 58,  1, 59, 57,  1, 56, 43, 60, 43, 52, 45, 43,  1, 58, 46, 47, 57,\n",
      "         1, 61, 47, 58, 46,  0, 53, 59, 56,  1, 54, 47, 49, 43, 57,  6,  1, 43,\n",
      "        56, 43,  1, 61, 43,  1, 40, 43, 41, 53, 51, 43,  1, 56, 39, 49, 43, 57,\n",
      "        10,  1, 44, 53, 56,  1, 58, 46, 43,  1, 45, 53, 42, 57,  1, 49, 52, 53,\n",
      "        61,  1, 21,  0, 57, 54, 43, 39, 49,  1, 58, 46, 47, 57,  1, 47, 52,  1,\n",
      "        46, 59, 52, 45, 43, 56,  1, 44, 53, 56,  1, 40, 56, 43, 39, 42,  6,  1,\n",
      "        52, 53, 58,  1, 47, 52,  1, 58, 46, 47, 56, 57, 58,  1, 44, 53, 56,  1,\n",
      "        56, 43, 60, 43, 52, 45, 43,  8,  0,  0])\n"
     ]
    }
   ],
   "source": [
    "# let's now encode the entire text dataset and store it into a torch.Tensor\n",
    "import torch # we use PyTorch: https://pytorch.org\n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "print(data.shape, data.dtype)\n",
    "print(data[:1000]) # the 1000 characters we looked at earier will to the GPT look like this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c5cb514c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's now split up the data into train and validation sets\n",
    "n = int(0.9*len(data)) # first 90% will be train, rest val\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7502aeb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_size = 8\n",
    "train_data[:block_size+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2e3e3c20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when input is tensor([18]) the target: 47\n",
      "when input is tensor([18, 47]) the target: 56\n",
      "when input is tensor([18, 47, 56]) the target: 57\n",
      "when input is tensor([18, 47, 56, 57]) the target: 58\n",
      "when input is tensor([18, 47, 56, 57, 58]) the target: 1\n",
      "when input is tensor([18, 47, 56, 57, 58,  1]) the target: 15\n",
      "when input is tensor([18, 47, 56, 57, 58,  1, 15]) the target: 47\n",
      "when input is tensor([18, 47, 56, 57, 58,  1, 15, 47]) the target: 58\n"
     ]
    }
   ],
   "source": [
    "x = train_data[:block_size]\n",
    "y = train_data[1:block_size+1]\n",
    "for t in range(block_size):\n",
    "    context = x[:t+1]\n",
    "    target = y[t]\n",
    "    print(f\"when input is {context} the target: {target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7bfcdd3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:\n",
      "torch.Size([4, 8])\n",
      "tensor([[53, 59,  6,  1, 58, 56, 47, 40],\n",
      "        [49, 43, 43, 54,  1, 47, 58,  1],\n",
      "        [13, 52, 45, 43, 50, 53,  8,  0],\n",
      "        [ 1, 39,  1, 46, 53, 59, 57, 43]])\n",
      "targets:\n",
      "torch.Size([4, 8])\n",
      "tensor([[59,  6,  1, 58, 56, 47, 40, 59],\n",
      "        [43, 43, 54,  1, 47, 58,  1, 58],\n",
      "        [52, 45, 43, 50, 53,  8,  0, 26],\n",
      "        [39,  1, 46, 53, 59, 57, 43,  0]])\n",
      "----\n",
      "when input is [53] the target: 59\n",
      "when input is [53, 59] the target: 6\n",
      "when input is [53, 59, 6] the target: 1\n",
      "when input is [53, 59, 6, 1] the target: 58\n",
      "when input is [53, 59, 6, 1, 58] the target: 56\n",
      "when input is [53, 59, 6, 1, 58, 56] the target: 47\n",
      "when input is [53, 59, 6, 1, 58, 56, 47] the target: 40\n",
      "when input is [53, 59, 6, 1, 58, 56, 47, 40] the target: 59\n",
      "when input is [49] the target: 43\n",
      "when input is [49, 43] the target: 43\n",
      "when input is [49, 43, 43] the target: 54\n",
      "when input is [49, 43, 43, 54] the target: 1\n",
      "when input is [49, 43, 43, 54, 1] the target: 47\n",
      "when input is [49, 43, 43, 54, 1, 47] the target: 58\n",
      "when input is [49, 43, 43, 54, 1, 47, 58] the target: 1\n",
      "when input is [49, 43, 43, 54, 1, 47, 58, 1] the target: 58\n",
      "when input is [13] the target: 52\n",
      "when input is [13, 52] the target: 45\n",
      "when input is [13, 52, 45] the target: 43\n",
      "when input is [13, 52, 45, 43] the target: 50\n",
      "when input is [13, 52, 45, 43, 50] the target: 53\n",
      "when input is [13, 52, 45, 43, 50, 53] the target: 8\n",
      "when input is [13, 52, 45, 43, 50, 53, 8] the target: 0\n",
      "when input is [13, 52, 45, 43, 50, 53, 8, 0] the target: 26\n",
      "when input is [1] the target: 39\n",
      "when input is [1, 39] the target: 1\n",
      "when input is [1, 39, 1] the target: 46\n",
      "when input is [1, 39, 1, 46] the target: 53\n",
      "when input is [1, 39, 1, 46, 53] the target: 59\n",
      "when input is [1, 39, 1, 46, 53, 59] the target: 57\n",
      "when input is [1, 39, 1, 46, 53, 59, 57] the target: 43\n",
      "when input is [1, 39, 1, 46, 53, 59, 57, 43] the target: 0\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1337)\n",
    "batch_size = 4 # how many independent sequences will we process in parallel?\n",
    "block_size = 8 # what is the maximum context length for predictions?\n",
    "\n",
    "def get_batch(split):\n",
    "    # generate a small batch of data of inputs x and targets y\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    return x, y\n",
    "\n",
    "xb, yb = get_batch('train')\n",
    "print('inputs:')\n",
    "print(xb.shape)\n",
    "print(xb)\n",
    "print('targets:')\n",
    "print(yb.shape)\n",
    "print(yb)\n",
    "\n",
    "print('----')\n",
    "\n",
    "for b in range(batch_size): # batch dimension\n",
    "    for t in range(block_size): # time dimension\n",
    "        context = xb[b, :t+1]\n",
    "        target = yb[b,t]\n",
    "        print(f\"when input is {context.tolist()} the target: {target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0d425382",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[53, 59,  6,  1, 58, 56, 47, 40],\n",
      "        [49, 43, 43, 54,  1, 47, 58,  1],\n",
      "        [13, 52, 45, 43, 50, 53,  8,  0],\n",
      "        [ 1, 39,  1, 46, 53, 59, 57, 43]])\n"
     ]
    }
   ],
   "source": [
    "print(xb) # our input to the transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "08c80013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 65])\n",
      "tensor(4.8948, grad_fn=<NllLossBackward0>)\n",
      "\n",
      "Sr?qP-QWktXoL&jLDJgOLVz'RIoDqHdhsV&vLLxatjscMpwLERSPyao.qfzs$Ys$zF-w,;eEkzxjgCKFChs!iWW.ObzDnxA Ms$3\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "torch.manual_seed(1337)\n",
    "\n",
    "class BigramLanguageModel(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        # each token directly reads off the logits for the next token from a lookup table\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "\n",
    "        # idx and targets are both (B,T) tensor of integers\n",
    "        logits = self.token_embedding_table(idx) # (B,T,C)\n",
    "        \n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "\n",
    "        return logits, loss\n",
    "    \n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        # idx is (B, T) array of indices in the current context\n",
    "        for _ in range(max_new_tokens):\n",
    "            # get the predictions\n",
    "            logits, loss = self(idx)\n",
    "            # focus only on the last time step\n",
    "            logits = logits[:, -1, :] # becomes (B, C)\n",
    "            # apply softmax to get probabilities\n",
    "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
    "            # sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
    "            # append sampled index to the running sequence\n",
    "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
    "        return idx\n",
    "\n",
    "m = BigramLanguageModel(65)\n",
    "logits, loss = m(xb, yb)\n",
    "print(logits.shape)\n",
    "print(loss)\n",
    "\n",
    "print(decode(m.generate(idx = torch.zeros((1, 1), dtype=torch.long), max_new_tokens=100)[0].tolist()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f914593b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[46, 47, 47, 1, 58, 46, 43, 56, 43]\n",
      "hii there\n"
     ]
    }
   ],
   "source": [
    "# create a mapping from characters to integers\n",
    "stoi = { ch:i for i,ch in enumerate(chars) }\n",
    "itos = { i:ch for i,ch in enumerate(chars) }\n",
    "encode = lambda s: [stoi[c] for c in s] # encoder: take a string, output a list of integers\n",
    "decode = lambda l: ''.join([itos[i] for i in l]) # decoder: take a list of integers, output a string\n",
    "\n",
    "print(encode(\"hii there\"))\n",
    "print(decode(encode(\"hii there\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "46d7615e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1115393]) torch.int64\n",
      "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
      "         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,\n",
      "        57, 54, 43, 39, 49,  8,  0,  0, 13, 50, 50, 10,  0, 31, 54, 43, 39, 49,\n",
      "         6,  1, 57, 54, 43, 39, 49,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47,\n",
      "        58, 47, 64, 43, 52, 10,  0, 37, 53, 59,  1, 39, 56, 43,  1, 39, 50, 50,\n",
      "         1, 56, 43, 57, 53, 50, 60, 43, 42,  1, 56, 39, 58, 46, 43, 56,  1, 58,\n",
      "        53,  1, 42, 47, 43,  1, 58, 46, 39, 52,  1, 58, 53,  1, 44, 39, 51, 47,\n",
      "        57, 46, 12,  0,  0, 13, 50, 50, 10,  0, 30, 43, 57, 53, 50, 60, 43, 42,\n",
      "         8,  1, 56, 43, 57, 53, 50, 60, 43, 42,  8,  0,  0, 18, 47, 56, 57, 58,\n",
      "         1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 18, 47, 56, 57, 58,  6,  1, 63,\n",
      "        53, 59,  1, 49, 52, 53, 61,  1, 15, 39, 47, 59, 57,  1, 25, 39, 56, 41,\n",
      "        47, 59, 57,  1, 47, 57,  1, 41, 46, 47, 43, 44,  1, 43, 52, 43, 51, 63,\n",
      "         1, 58, 53,  1, 58, 46, 43,  1, 54, 43, 53, 54, 50, 43,  8,  0,  0, 13,\n",
      "        50, 50, 10,  0, 35, 43,  1, 49, 52, 53, 61,  5, 58,  6,  1, 61, 43,  1,\n",
      "        49, 52, 53, 61,  5, 58,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47, 58,\n",
      "        47, 64, 43, 52, 10,  0, 24, 43, 58,  1, 59, 57,  1, 49, 47, 50, 50,  1,\n",
      "        46, 47, 51,  6,  1, 39, 52, 42,  1, 61, 43,  5, 50, 50,  1, 46, 39, 60,\n",
      "        43,  1, 41, 53, 56, 52,  1, 39, 58,  1, 53, 59, 56,  1, 53, 61, 52,  1,\n",
      "        54, 56, 47, 41, 43,  8,  0, 21, 57,  5, 58,  1, 39,  1, 60, 43, 56, 42,\n",
      "        47, 41, 58, 12,  0,  0, 13, 50, 50, 10,  0, 26, 53,  1, 51, 53, 56, 43,\n",
      "         1, 58, 39, 50, 49, 47, 52, 45,  1, 53, 52,  5, 58, 11,  1, 50, 43, 58,\n",
      "         1, 47, 58,  1, 40, 43,  1, 42, 53, 52, 43, 10,  1, 39, 61, 39, 63,  6,\n",
      "         1, 39, 61, 39, 63,  2,  0,  0, 31, 43, 41, 53, 52, 42,  1, 15, 47, 58,\n",
      "        47, 64, 43, 52, 10,  0, 27, 52, 43,  1, 61, 53, 56, 42,  6,  1, 45, 53,\n",
      "        53, 42,  1, 41, 47, 58, 47, 64, 43, 52, 57,  8,  0,  0, 18, 47, 56, 57,\n",
      "        58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 35, 43,  1, 39, 56, 43,  1,\n",
      "        39, 41, 41, 53, 59, 52, 58, 43, 42,  1, 54, 53, 53, 56,  1, 41, 47, 58,\n",
      "        47, 64, 43, 52, 57,  6,  1, 58, 46, 43,  1, 54, 39, 58, 56, 47, 41, 47,\n",
      "        39, 52, 57,  1, 45, 53, 53, 42,  8,  0, 35, 46, 39, 58,  1, 39, 59, 58,\n",
      "        46, 53, 56, 47, 58, 63,  1, 57, 59, 56, 44, 43, 47, 58, 57,  1, 53, 52,\n",
      "         1, 61, 53, 59, 50, 42,  1, 56, 43, 50, 47, 43, 60, 43,  1, 59, 57, 10,\n",
      "         1, 47, 44,  1, 58, 46, 43, 63,  0, 61, 53, 59, 50, 42,  1, 63, 47, 43,\n",
      "        50, 42,  1, 59, 57,  1, 40, 59, 58,  1, 58, 46, 43,  1, 57, 59, 54, 43,\n",
      "        56, 44, 50, 59, 47, 58, 63,  6,  1, 61, 46, 47, 50, 43,  1, 47, 58,  1,\n",
      "        61, 43, 56, 43,  0, 61, 46, 53, 50, 43, 57, 53, 51, 43,  6,  1, 61, 43,\n",
      "         1, 51, 47, 45, 46, 58,  1, 45, 59, 43, 57, 57,  1, 58, 46, 43, 63,  1,\n",
      "        56, 43, 50, 47, 43, 60, 43, 42,  1, 59, 57,  1, 46, 59, 51, 39, 52, 43,\n",
      "        50, 63, 11,  0, 40, 59, 58,  1, 58, 46, 43, 63,  1, 58, 46, 47, 52, 49,\n",
      "         1, 61, 43,  1, 39, 56, 43,  1, 58, 53, 53,  1, 42, 43, 39, 56, 10,  1,\n",
      "        58, 46, 43,  1, 50, 43, 39, 52, 52, 43, 57, 57,  1, 58, 46, 39, 58,  0,\n",
      "        39, 44, 44, 50, 47, 41, 58, 57,  1, 59, 57,  6,  1, 58, 46, 43,  1, 53,\n",
      "        40, 48, 43, 41, 58,  1, 53, 44,  1, 53, 59, 56,  1, 51, 47, 57, 43, 56,\n",
      "        63,  6,  1, 47, 57,  1, 39, 57,  1, 39, 52,  0, 47, 52, 60, 43, 52, 58,\n",
      "        53, 56, 63,  1, 58, 53,  1, 54, 39, 56, 58, 47, 41, 59, 50, 39, 56, 47,\n",
      "        57, 43,  1, 58, 46, 43, 47, 56,  1, 39, 40, 59, 52, 42, 39, 52, 41, 43,\n",
      "        11,  1, 53, 59, 56,  0, 57, 59, 44, 44, 43, 56, 39, 52, 41, 43,  1, 47,\n",
      "        57,  1, 39,  1, 45, 39, 47, 52,  1, 58, 53,  1, 58, 46, 43, 51,  1, 24,\n",
      "        43, 58,  1, 59, 57,  1, 56, 43, 60, 43, 52, 45, 43,  1, 58, 46, 47, 57,\n",
      "         1, 61, 47, 58, 46,  0, 53, 59, 56,  1, 54, 47, 49, 43, 57,  6,  1, 43,\n",
      "        56, 43,  1, 61, 43,  1, 40, 43, 41, 53, 51, 43,  1, 56, 39, 49, 43, 57,\n",
      "        10,  1, 44, 53, 56,  1, 58, 46, 43,  1, 45, 53, 42, 57,  1, 49, 52, 53,\n",
      "        61,  1, 21,  0, 57, 54, 43, 39, 49,  1, 58, 46, 47, 57,  1, 47, 52,  1,\n",
      "        46, 59, 52, 45, 43, 56,  1, 44, 53, 56,  1, 40, 56, 43, 39, 42,  6,  1,\n",
      "        52, 53, 58,  1, 47, 52,  1, 58, 46, 47, 56, 57, 58,  1, 44, 53, 56,  1,\n",
      "        56, 43, 60, 43, 52, 45, 43,  8,  0,  0])\n"
     ]
    }
   ],
   "source": [
    "# let's now encode the entire text dataset and store it into a torch.Tensor\n",
    "import torch # we use PyTorch: https://pytorch.org\n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "print(data.shape, data.dtype)\n",
    "print(data[:1000]) # the 1000 characters we looked at earier will to the GPT look like this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "655ae1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's now split up the data into train and validation sets\n",
    "n = int(0.9*len(data)) # first 90% will be train, rest val\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3959e8d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_size = 8\n",
    "train_data[:block_size+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e1604528",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when input is tensor([18]) the target: 47\n",
      "when input is tensor([18, 47]) the target: 56\n",
      "when input is tensor([18, 47, 56]) the target: 57\n",
      "when input is tensor([18, 47, 56, 57]) the target: 58\n",
      "when input is tensor([18, 47, 56, 57, 58]) the target: 1\n",
      "when input is tensor([18, 47, 56, 57, 58,  1]) the target: 15\n",
      "when input is tensor([18, 47, 56, 57, 58,  1, 15]) the target: 47\n",
      "when input is tensor([18, 47, 56, 57, 58,  1, 15, 47]) the target: 58\n"
     ]
    }
   ],
   "source": [
    "x = train_data[:block_size]\n",
    "y = train_data[1:block_size+1]\n",
    "for t in range(block_size):\n",
    "    context = x[:t+1]\n",
    "    target = y[t]\n",
    "    print(f\"when input is {context} the target: {target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bb6ec1ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:\n",
      "torch.Size([4, 8])\n",
      "tensor([[53, 59,  6,  1, 58, 56, 47, 40],\n",
      "        [49, 43, 43, 54,  1, 47, 58,  1],\n",
      "        [13, 52, 45, 43, 50, 53,  8,  0],\n",
      "        [ 1, 39,  1, 46, 53, 59, 57, 43]])\n",
      "targets:\n",
      "torch.Size([4, 8])\n",
      "tensor([[59,  6,  1, 58, 56, 47, 40, 59],\n",
      "        [43, 43, 54,  1, 47, 58,  1, 58],\n",
      "        [52, 45, 43, 50, 53,  8,  0, 26],\n",
      "        [39,  1, 46, 53, 59, 57, 43,  0]])\n",
      "----\n",
      "when input is [53] the target: 59\n",
      "when input is [53, 59] the target: 6\n",
      "when input is [53, 59, 6] the target: 1\n",
      "when input is [53, 59, 6, 1] the target: 58\n",
      "when input is [53, 59, 6, 1, 58] the target: 56\n",
      "when input is [53, 59, 6, 1, 58, 56] the target: 47\n",
      "when input is [53, 59, 6, 1, 58, 56, 47] the target: 40\n",
      "when input is [53, 59, 6, 1, 58, 56, 47, 40] the target: 59\n",
      "when input is [49] the target: 43\n",
      "when input is [49, 43] the target: 43\n",
      "when input is [49, 43, 43] the target: 54\n",
      "when input is [49, 43, 43, 54] the target: 1\n",
      "when input is [49, 43, 43, 54, 1] the target: 47\n",
      "when input is [49, 43, 43, 54, 1, 47] the target: 58\n",
      "when input is [49, 43, 43, 54, 1, 47, 58] the target: 1\n",
      "when input is [49, 43, 43, 54, 1, 47, 58, 1] the target: 58\n",
      "when input is [13] the target: 52\n",
      "when input is [13, 52] the target: 45\n",
      "when input is [13, 52, 45] the target: 43\n",
      "when input is [13, 52, 45, 43] the target: 50\n",
      "when input is [13, 52, 45, 43, 50] the target: 53\n",
      "when input is [13, 52, 45, 43, 50, 53] the target: 8\n",
      "when input is [13, 52, 45, 43, 50, 53, 8] the target: 0\n",
      "when input is [13, 52, 45, 43, 50, 53, 8, 0] the target: 26\n",
      "when input is [1] the target: 39\n",
      "when input is [1, 39] the target: 1\n",
      "when input is [1, 39, 1] the target: 46\n",
      "when input is [1, 39, 1, 46] the target: 53\n",
      "when input is [1, 39, 1, 46, 53] the target: 59\n",
      "when input is [1, 39, 1, 46, 53, 59] the target: 57\n",
      "when input is [1, 39, 1, 46, 53, 59, 57] the target: 43\n",
      "when input is [1, 39, 1, 46, 53, 59, 57, 43] the target: 0\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1337)\n",
    "batch_size = 4 # how many independent sequences will we process in parallel?\n",
    "block_size = 8 # what is the maximum context length for predictions?\n",
    "\n",
    "def get_batch(split):\n",
    "    # generate a small batch of data of inputs x and targets y\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    return x, y\n",
    "\n",
    "xb, yb = get_batch('train')\n",
    "print('inputs:')\n",
    "print(xb.shape)\n",
    "print(xb)\n",
    "print('targets:')\n",
    "print(yb.shape)\n",
    "print(yb)\n",
    "\n",
    "print('----')\n",
    "\n",
    "for b in range(batch_size): # batch dimension\n",
    "    for t in range(block_size): # time dimension\n",
    "        context = xb[b, :t+1]\n",
    "        target = yb[b,t]\n",
    "        print(f\"when input is {context.tolist()} the target: {target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c1ade7c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[53, 59,  6,  1, 58, 56, 47, 40],\n",
      "        [49, 43, 43, 54,  1, 47, 58,  1],\n",
      "        [13, 52, 45, 43, 50, 53,  8,  0],\n",
      "        [ 1, 39,  1, 46, 53, 59, 57, 43]])\n"
     ]
    }
   ],
   "source": [
    "print(xb) # our input to the transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b845e8a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 65])\n",
      "tensor(4.8948, grad_fn=<NllLossBackward0>)\n",
      "\n",
      "Sr?qP-QWktXoL&jLDJgOLVz'RIoDqHdhsV&vLLxatjscMpwLERSPyao.qfzs$Ys$zF-w,;eEkzxjgCKFChs!iWW.ObzDnxA Ms$3\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "torch.manual_seed(1337)\n",
    "\n",
    "class BigramLanguageModel(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        # each token directly reads off the logits for the next token from a lookup table\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "\n",
    "        # idx and targets are both (B,T) tensor of integers\n",
    "        logits = self.token_embedding_table(idx) # (B,T,C)\n",
    "        \n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "\n",
    "        return logits, loss\n",
    "    \n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        # idx is (B, T) array of indices in the current context\n",
    "        for _ in range(max_new_tokens):\n",
    "            # get the predictions\n",
    "            logits, loss = self(idx)\n",
    "            # focus only on the last time step\n",
    "            logits = logits[:, -1, :] # becomes (B, C)\n",
    "            # apply softmax to get probabilities\n",
    "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
    "            # sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
    "            # append sampled index to the running sequence\n",
    "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
    "        return idx\n",
    "\n",
    "m = BigramLanguageModel(65)\n",
    "logits, loss = m(xb, yb)\n",
    "print(logits.shape)\n",
    "print(loss)\n",
    "\n",
    "print(decode(m.generate(idx = torch.zeros((1, 1), dtype=torch.long), max_new_tokens=100)[0].tolist()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "08703e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a PyTorch optimizer\n",
    "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1855b79e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.578680038452148\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "for steps in range(100): # increase number of steps for good results... \n",
    "    \n",
    "    # sample a batch of data\n",
    "    xb, yb = get_batch('train')\n",
    "\n",
    "    # evaluate the loss\n",
    "    logits, loss = m(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "print(loss.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "14a3042f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "xiKi-RJ:COpVuUa!U?qMH.uk!sCuMXvv!CJFfx;LgRyJknOEti.?I&-gPlLyulId?XlaInQ'q,lT$\n",
      "3Q&sGlvHQ?mqSq-eON\n",
      "x?SP fUAfCAuCX:bOlgiRQWN:Mphaw\n",
      "tRLKuYXEaAXxrcq-gCUzeh3w!AcyaylgYWjmJM?Uzw:inaY,:C&OECW:vmGGJAn3onAuMgia!ms$Vb q-gCOcPcUhOnxJGUGSPJWT:.?ujmJFoiNL&A'DxY,prZ?qdT;hoo'dHooXXlxf'WkHK&u3Q?rqUi.kz;?Yx?C&u3Qbfzxlyh'Vl:zyxjKXgC?\n",
      "lv'QKFiBeviNxO'm!Upm$srm&TqViqiBD3HBP!juEOpmZJyF$Fwfy!PlvWPFC\n",
      "&WDdP!Ko,px\n",
      "x\n",
      "tREOE;AJ.BeXkylOVD3KHp$e?nj,.SFbWWI'ubcL!q-tU;aXmJ&uGXHxJXI&Z!gHRpajj;l.\n",
      "pTErIBjx;JKIgoCnLGXrJSP!AU-AcbczR?\n"
     ]
    }
   ],
   "source": [
    "print(decode(m.generate(idx = torch.zeros((1, 1), dtype=torch.long), max_new_tokens=500)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5514f2fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a=\n",
      "tensor([[1.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333]])\n",
      "--\n",
      "b=\n",
      "tensor([[2., 7.],\n",
      "        [6., 4.],\n",
      "        [6., 5.]])\n",
      "--\n",
      "c=\n",
      "tensor([[2.0000, 7.0000],\n",
      "        [4.0000, 5.5000],\n",
      "        [4.6667, 5.3333]])\n"
     ]
    }
   ],
   "source": [
    "# toy example illustrating how matrix multiplication can be used for a \"weighted aggregation\"\n",
    "torch.manual_seed(42)\n",
    "a = torch.tril(torch.ones(3, 3))\n",
    "a = a / torch.sum(a, 1, keepdim=True)\n",
    "b = torch.randint(0,10,(3,2)).float()\n",
    "c = a @ b\n",
    "print('a=')\n",
    "print(a)\n",
    "print('--')\n",
    "print('b=')\n",
    "print(b)\n",
    "print('--')\n",
    "print('c=')\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b194aa96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 2])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# consider the following toy example:\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "B,T,C = 4,8,2 # batch, time, channels\n",
    "x = torch.randn(B,T,C)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ac66880a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want x[b,t] = mean_{i<=t} x[b,i]\n",
    "xbow = torch.zeros((B,T,C))\n",
    "for b in range(B):\n",
    "    for t in range(T):\n",
    "        xprev = x[b,:t+1] # (t,C)\n",
    "        xbow[b,t] = torch.mean(xprev, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d2474d52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# version 2: using matrix multiply for a weighted aggregation\n",
    "wei = torch.tril(torch.ones(T, T))\n",
    "wei = wei / wei.sum(1, keepdim=True)\n",
    "xbow2 = wei @ x # (B, T, T) @ (B, T, C) ----> (B, T, C)\n",
    "torch.allclose(xbow, xbow2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a4cb3b0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# version 3: use Softmax\n",
    "tril = torch.tril(torch.ones(T, T))\n",
    "wei = torch.zeros((T,T))\n",
    "wei = wei.masked_fill(tril == 0, float('-inf'))\n",
    "wei = F.softmax(wei, dim=-1)\n",
    "xbow3 = wei @ x\n",
    "torch.allclose(xbow, xbow3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "507560db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 16])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# version 4: self-attention!\n",
    "torch.manual_seed(1337)\n",
    "B,T,C = 4,8,32 # batch, time, channels\n",
    "x = torch.randn(B,T,C)\n",
    "\n",
    "# let's see a single Head perform self-attention\n",
    "head_size = 16\n",
    "key = nn.Linear(C, head_size, bias=False)\n",
    "query = nn.Linear(C, head_size, bias=False)\n",
    "value = nn.Linear(C, head_size, bias=False)\n",
    "k = key(x)   # (B, T, 16)\n",
    "q = query(x) # (B, T, 16)\n",
    "wei =  q @ k.transpose(-2, -1) # (B, T, 16) @ (B, 16, T) ---> (B, T, T)\n",
    "\n",
    "tril = torch.tril(torch.ones(T, T))\n",
    "#wei = torch.zeros((T,T))\n",
    "wei = wei.masked_fill(tril == 0, float('-inf'))\n",
    "wei = F.softmax(wei, dim=-1)\n",
    "\n",
    "v = value(x)\n",
    "out = wei @ v\n",
    "#out = wei @ x\n",
    "\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d372be49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.1574, 0.8426, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2088, 0.1646, 0.6266, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.5792, 0.1187, 0.1889, 0.1131, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0294, 0.1052, 0.0469, 0.0276, 0.7909, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0176, 0.2689, 0.0215, 0.0089, 0.6812, 0.0019, 0.0000, 0.0000],\n",
       "        [0.1691, 0.4066, 0.0438, 0.0416, 0.1048, 0.2012, 0.0329, 0.0000],\n",
       "        [0.0210, 0.0843, 0.0555, 0.2297, 0.0573, 0.0709, 0.2423, 0.2391]],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wei[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "359f8d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = torch.randn(B,T,head_size)\n",
    "q = torch.randn(B,T,head_size)\n",
    "wei = q @ k.transpose(-2, -1) * head_size**-0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5aab31c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0449)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "77648a3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0700)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b4a73729",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0918)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wei.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0611f28a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1925, 0.1426, 0.2351, 0.1426, 0.2872])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.softmax(torch.tensor([0.1, -0.2, 0.3, -0.2, 0.5]), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "46b97ec5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0326, 0.0030, 0.1615, 0.0030, 0.8000])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.softmax(torch.tensor([0.1, -0.2, 0.3, -0.2, 0.5])*8, dim=-1) # gets too peaky, converges to one-hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1b0f30ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 100])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class LayerNorm1d: # (used to be BatchNorm1d)\n",
    "  \n",
    "  def __init__(self, dim, eps=1e-5, momentum=0.1):\n",
    "    self.eps = eps\n",
    "    self.gamma = torch.ones(dim)\n",
    "    self.beta = torch.zeros(dim)\n",
    "  \n",
    "  def __call__(self, x):\n",
    "    # calculate the forward pass\n",
    "    xmean = x.mean(1, keepdim=True) # batch mean\n",
    "    xvar = x.var(1, keepdim=True) # batch variance\n",
    "    xhat = (x - xmean) / torch.sqrt(xvar + self.eps) # normalize to unit variance\n",
    "    self.out = self.gamma * xhat + self.beta\n",
    "    return self.out\n",
    "  \n",
    "  def parameters(self):\n",
    "    return [self.gamma, self.beta]\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "module = LayerNorm1d(100)\n",
    "x = torch.randn(32, 100) # batch size 32 of 100-dimensional vectors\n",
    "x = module(x)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6ce41617",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.1469), tensor(0.8803))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:,0].mean(), x[:,0].std() # mean,std of one feature across all batch inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9fab4376",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-9.5367e-09), tensor(1.0000))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0,:].mean(), x[0,:].std() # mean,std of a single input from the batch, of its features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ef75147b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Full Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2ccb3d1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.209729 M parameters\n",
      "step 0: train loss 4.4112, val loss 4.4015\n",
      "step 100: train loss 2.6575, val loss 2.6631\n",
      "step 200: train loss 2.5120, val loss 2.5024\n",
      "step 300: train loss 2.4156, val loss 2.4309\n",
      "step 400: train loss 2.3509, val loss 2.3665\n",
      "step 500: train loss 2.3019, val loss 2.3231\n",
      "step 600: train loss 2.2555, val loss 2.2621\n",
      "step 700: train loss 2.2138, val loss 2.2237\n",
      "step 800: train loss 2.1598, val loss 2.1907\n",
      "step 900: train loss 2.1420, val loss 2.1517\n",
      "step 1000: train loss 2.1024, val loss 2.1320\n",
      "step 1100: train loss 2.0634, val loss 2.1141\n",
      "step 1200: train loss 2.0498, val loss 2.0976\n",
      "step 1300: train loss 2.0180, val loss 2.0631\n",
      "step 1400: train loss 2.0008, val loss 2.0469\n",
      "step 1500: train loss 1.9837, val loss 2.0376\n",
      "step 1600: train loss 1.9668, val loss 2.0405\n",
      "step 1700: train loss 1.9527, val loss 2.0325\n",
      "step 1800: train loss 1.9268, val loss 2.0226\n",
      "step 1900: train loss 1.9133, val loss 1.9874\n",
      "step 2000: train loss 1.9080, val loss 1.9977\n",
      "step 2100: train loss 1.8759, val loss 1.9716\n",
      "step 2200: train loss 1.8784, val loss 1.9667\n",
      "step 2300: train loss 1.8547, val loss 1.9590\n",
      "step 2400: train loss 1.8423, val loss 1.9441\n",
      "step 2500: train loss 1.8339, val loss 1.9426\n",
      "step 2600: train loss 1.8214, val loss 1.9367\n",
      "step 2700: train loss 1.8064, val loss 1.9387\n",
      "step 2800: train loss 1.7916, val loss 1.9276\n",
      "step 2900: train loss 1.7963, val loss 1.9358\n",
      "step 3000: train loss 1.7782, val loss 1.9101\n",
      "step 3100: train loss 1.7725, val loss 1.9039\n",
      "step 3200: train loss 1.7560, val loss 1.8944\n",
      "step 3300: train loss 1.7564, val loss 1.9006\n",
      "step 3400: train loss 1.7601, val loss 1.8946\n",
      "step 3500: train loss 1.7533, val loss 1.9032\n",
      "step 3600: train loss 1.7425, val loss 1.8937\n",
      "step 3700: train loss 1.7438, val loss 1.8863\n",
      "step 3800: train loss 1.7342, val loss 1.8935\n",
      "step 3900: train loss 1.7207, val loss 1.8711\n",
      "step 4000: train loss 1.7107, val loss 1.8618\n",
      "step 4100: train loss 1.7145, val loss 1.8562\n",
      "step 4200: train loss 1.7179, val loss 1.8582\n",
      "step 4300: train loss 1.7137, val loss 1.8526\n",
      "step 4400: train loss 1.6988, val loss 1.8624\n",
      "step 4500: train loss 1.6963, val loss 1.8503\n",
      "step 4600: train loss 1.6959, val loss 1.8423\n",
      "step 4700: train loss 1.6897, val loss 1.8327\n",
      "step 4800: train loss 1.6836, val loss 1.8444\n",
      "step 4900: train loss 1.6781, val loss 1.8314\n",
      "step 4999: train loss 1.6781, val loss 1.8305\n",
      "\n",
      "ROMEO:\n",
      "Begiars freight my seall I made upon thy nor I uDpracely mind of have your grance we\n",
      "Then mind born the gorrood upwon alond your\n",
      "Nowand think eyblent, seep hance pransted\n",
      "Do usame nother by, lord, it though, glentied, yit're so hadst wifter?\n",
      "\n",
      "THAS BILINGBRGHILI:\n",
      "To him, none thou sgentremment that they befoled\n",
      "His Lifest, sir.\n",
      "\n",
      "ISAHUS:\n",
      "Was thou saw thy chater the tage enderuble\n",
      "Doth must lest it?\n",
      "\n",
      "PUGLET:\n",
      "He was nayed is the broke enexeof?\n",
      "My not decre homing your ears wan marron\n",
      "His in foesir brook'd be slorce ways!\n",
      "Why, sirfors his will haso. Orso pardes us.\n",
      "\n",
      "LUCIO: as passon my prehishlemen else\n",
      "And fune manistrent, the minay of noter marry we canged that him\n",
      "Made is by jeclasure, lars! Larring ba-monde\n",
      "Nroncelies, for ways!\n",
      "He a redrumppinrition thereford gate:\n",
      "By for mo secome our and should wielre?\n",
      "\n",
      "DUTUERSTE-NIUS:\n",
      "I'll bear concer's-schargarl attan.\n",
      "\n",
      "BRUCKIO:\n",
      "O, then.\n",
      "\n",
      "BUTUGIELIET:\n",
      "This make diphording takes ya.\n",
      "\n",
      "GLOUCESTER:\n",
      "O the diod, now or childess execy with.\n",
      "\n",
      "GLOUCHY?\n",
      "\n",
      "ISABELLABETH:\n",
      "And in upon no musice the would pardful\n",
      "As your wayknowd for\n",
      "Prockes, asuntorscharged crovices.\n",
      "\n",
      "PULIET:\n",
      "O,-wreal and well seepprow--Plard,\n",
      "Whithen my worson you not marrow? welle like yourself.\n",
      "Why, that, of the librial, now Murdering sothrown the stists! of in thy is hander rathing a war,\n",
      "And if will proce by your gone, he'st,\n",
      "A do frull him with him: but so well\n",
      "indet: and death isurne arst I rooth that,\n",
      "I and by you here, near will resecure\n",
      "Bidar, he gelpied and made am him say?\n",
      "\n",
      "PETHOLUCY.\n",
      "\n",
      "CAPULET:\n",
      "Yourm if mine.\n",
      "\n",
      "MENEN:\n",
      "Ve attness as walt,\n",
      "The norforty of therefoly's quentof, know marf-banief;\n",
      "Tere Caple heim the world rayouls yout.\n",
      "\n",
      "PETER:\n",
      "I change,s o'er, the matter'st\n",
      "\n",
      "FLORIZEF:\n",
      "Ro me, sweeth pript with resemated upon mens\n",
      "He wefdir? weether pare feelp, by?\n",
      "\n",
      "RUKE OVIO:\n",
      "Your wiends this fallom in in in meephet,\n",
      "For York Romeo meance: I pray proward merciares surn mre; God, thereforing not shall: I such,\n",
      "What's can the 'himed? bight you blet flipasent,\n",
      "Then to\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "# hyperparameters\n",
    "batch_size = 16 # how many independent sequences will we process in parallel?\n",
    "block_size = 32 # what is the maximum context length for predictions?\n",
    "max_iters = 5000\n",
    "eval_interval = 100\n",
    "learning_rate = 1e-3\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "eval_iters = 200\n",
    "n_embd = 64\n",
    "n_head = 4\n",
    "n_layer = 4\n",
    "dropout = 0.0\n",
    "# ------------\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "\n",
    "# wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
    "with open('input.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "\n",
    "# here are all the unique characters that occur in this text\n",
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "# create a mapping from characters to integers\n",
    "stoi = { ch:i for i,ch in enumerate(chars) }\n",
    "itos = { i:ch for i,ch in enumerate(chars) }\n",
    "encode = lambda s: [stoi[c] for c in s] # encoder: take a string, output a list of integers\n",
    "decode = lambda l: ''.join([itos[i] for i in l]) # decoder: take a list of integers, output a string\n",
    "\n",
    "# Train and test splits\n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "n = int(0.9*len(data)) # first 90% will be train, rest val\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]\n",
    "\n",
    "# data loading\n",
    "def get_batch(split):\n",
    "    # generate a small batch of data of inputs x and targets y\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    return x, y\n",
    "\n",
    "@torch.no_grad()\n",
    "def estimate_loss():\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for split in ['train', 'val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X, Y = get_batch(split)\n",
    "            logits, loss = model(X, Y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train()\n",
    "    return out\n",
    "\n",
    "class Head(nn.Module):\n",
    "    \"\"\" one head of self-attention \"\"\"\n",
    "\n",
    "    def __init__(self, head_size):\n",
    "        super().__init__()\n",
    "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B,T,C = x.shape\n",
    "        k = self.key(x)   # (B,T,C)\n",
    "        q = self.query(x) # (B,T,C)\n",
    "        # compute attention scores (\"affinities\")\n",
    "        wei = q @ k.transpose(-2,-1) * C**-0.5 # (B, T, C) @ (B, C, T) -> (B, T, T)\n",
    "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf')) # (B, T, T)\n",
    "        wei = F.softmax(wei, dim=-1) # (B, T, T)\n",
    "        wei = self.dropout(wei)\n",
    "        # perform the weighted aggregation of the values\n",
    "        v = self.value(x) # (B,T,C)\n",
    "        out = wei @ v # (B, T, T) @ (B, T, C) -> (B, T, C)\n",
    "        return out\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    \"\"\" multiple heads of self-attention in parallel \"\"\"\n",
    "\n",
    "    def __init__(self, num_heads, head_size):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
    "        self.proj = nn.Linear(n_embd, n_embd)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
    "        out = self.dropout(self.proj(out))\n",
    "        return out\n",
    "\n",
    "class FeedFoward(nn.Module):\n",
    "    \"\"\" a simple linear layer followed by a non-linearity \"\"\"\n",
    "\n",
    "    def __init__(self, n_embd):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(n_embd, 4 * n_embd),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4 * n_embd, n_embd),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class Block(nn.Module):\n",
    "    \"\"\" Transformer block: communication followed by computation \"\"\"\n",
    "\n",
    "    def __init__(self, n_embd, n_head):\n",
    "        # n_embd: embedding dimension, n_head: the number of heads we'd like\n",
    "        super().__init__()\n",
    "        head_size = n_embd // n_head\n",
    "        self.sa = MultiHeadAttention(n_head, head_size)\n",
    "        self.ffwd = FeedFoward(n_embd)\n",
    "        self.ln1 = nn.LayerNorm(n_embd)\n",
    "        self.ln2 = nn.LayerNorm(n_embd)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.sa(self.ln1(x))\n",
    "        x = x + self.ffwd(self.ln2(x))\n",
    "        return x\n",
    "\n",
    "# super simple bigram model\n",
    "class BigramLanguageModel(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # each token directly reads off the logits for the next token from a lookup table\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
    "        self.position_embedding_table = nn.Embedding(block_size, n_embd)\n",
    "        self.blocks = nn.Sequential(*[Block(n_embd, n_head=n_head) for _ in range(n_layer)])\n",
    "        self.ln_f = nn.LayerNorm(n_embd) # final layer norm\n",
    "        self.lm_head = nn.Linear(n_embd, vocab_size)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        B, T = idx.shape\n",
    "\n",
    "        # idx and targets are both (B,T) tensor of integers\n",
    "        tok_emb = self.token_embedding_table(idx) # (B,T,C)\n",
    "        pos_emb = self.position_embedding_table(torch.arange(T, device=device)) # (T,C)\n",
    "        x = tok_emb + pos_emb # (B,T,C)\n",
    "        x = self.blocks(x) # (B,T,C)\n",
    "        x = self.ln_f(x) # (B,T,C)\n",
    "        logits = self.lm_head(x) # (B,T,vocab_size)\n",
    "\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "\n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        # idx is (B, T) array of indices in the current context\n",
    "        for _ in range(max_new_tokens):\n",
    "            # crop idx to the last block_size tokens\n",
    "            idx_cond = idx[:, -block_size:]\n",
    "            # get the predictions\n",
    "            logits, loss = self(idx_cond)\n",
    "            # focus only on the last time step\n",
    "            logits = logits[:, -1, :] # becomes (B, C)\n",
    "            # apply softmax to get probabilities\n",
    "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
    "            # sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
    "            # append sampled index to the running sequence\n",
    "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
    "        return idx\n",
    "\n",
    "model = BigramLanguageModel()\n",
    "m = model.to(device)\n",
    "# print the number of parameters in the model\n",
    "print(sum(p.numel() for p in m.parameters())/1e6, 'M parameters')\n",
    "\n",
    "# create a PyTorch optimizer\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for iter in range(max_iters):\n",
    "\n",
    "    # every once in a while evaluate the loss on train and val sets\n",
    "    if iter % eval_interval == 0 or iter == max_iters - 1:\n",
    "        losses = estimate_loss()\n",
    "        print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
    "\n",
    "    # sample a batch of data\n",
    "    xb, yb = get_batch('train')\n",
    "\n",
    "    # evaluate the loss\n",
    "    logits, loss = model(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "# generate from the model\n",
    "context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
    "print(decode(m.generate(context, max_new_tokens=2000)[0].tolist()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd404cd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\dinak\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\dinak\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d785b254",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting tensorflow\n",
      "  Obtaining dependency information for tensorflow from https://files.pythonhosted.org/packages/93/21/9b035a4f823d6aee2917c75415be9a95861ff3d73a0a65e48edbf210cec1/tensorflow-2.15.0-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading tensorflow-2.15.0-cp311-cp311-win_amd64.whl.metadata (3.6 kB)\n",
      "Collecting tensorflow-intel==2.15.0 (from tensorflow)\n",
      "  Obtaining dependency information for tensorflow-intel==2.15.0 from https://files.pythonhosted.org/packages/4c/48/1a5a15517f18eaa4ff8d598b1c000300b20c1bb0e624539d702117a0c369/tensorflow_intel-2.15.0-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading tensorflow_intel-2.15.0-cp311-cp311-win_amd64.whl.metadata (5.1 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow-intel==2.15.0->tensorflow)\n",
      "  Obtaining dependency information for absl-py>=1.0.0 from https://files.pythonhosted.org/packages/a2/ad/e0d3c824784ff121c03cc031f944bc7e139a8f1870ffd2845cc2dd76f6c4/absl_py-2.1.0-py3-none-any.whl.metadata\n",
      "  Downloading absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow-intel==2.15.0->tensorflow)\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting flatbuffers>=23.5.26 (from tensorflow-intel==2.15.0->tensorflow)\n",
      "  Obtaining dependency information for flatbuffers>=23.5.26 from https://files.pythonhosted.org/packages/6f/12/d5c79ee252793ffe845d58a913197bfa02ae9a0b5c9bc3dc4b58d477b9e7/flatbuffers-23.5.26-py2.py3-none-any.whl.metadata\n",
      "  Downloading flatbuffers-23.5.26-py2.py3-none-any.whl.metadata (850 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow-intel==2.15.0->tensorflow)\n",
      "  Downloading gast-0.5.4-py3-none-any.whl (19 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow-intel==2.15.0->tensorflow)\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "     ---------------------------------------- 0.0/57.5 kB ? eta -:--:--\n",
      "     ---------------------------------------- 57.5/57.5 kB 3.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (3.7.0)\n",
      "Collecting libclang>=13.0.0 (from tensorflow-intel==2.15.0->tensorflow)\n",
      "  Obtaining dependency information for libclang>=13.0.0 from https://files.pythonhosted.org/packages/02/8c/dc970bc00867fe290e8c8a7befa1635af716a9ebdfe3fb9dce0ca4b522ce/libclang-16.0.6-py2.py3-none-win_amd64.whl.metadata\n",
      "  Downloading libclang-16.0.6-py2.py3-none-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting ml-dtypes~=0.2.0 (from tensorflow-intel==2.15.0->tensorflow)\n",
      "  Obtaining dependency information for ml-dtypes~=0.2.0 from https://files.pythonhosted.org/packages/08/89/c727fde1a3d12586e0b8c01abf53754707d76beaa9987640e70807d4545f/ml_dtypes-0.2.0-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading ml_dtypes-0.2.0-cp311-cp311-win_amd64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.24.3)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow-intel==2.15.0->tensorflow)\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "     ---------------------------------------- 0.0/65.5 kB ? eta -:--:--\n",
      "     ---------------------------------------- 65.5/65.5 kB 3.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: packaging in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (23.0)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 (from tensorflow-intel==2.15.0->tensorflow)\n",
      "  Obtaining dependency information for protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 from https://files.pythonhosted.org/packages/c1/00/c3ae19cabb36cfabc94ff0b102aac21b471c9f91a1357f8aafffb9efe8e0/protobuf-4.25.2-cp310-abi3-win_amd64.whl.metadata\n",
      "  Downloading protobuf-4.25.2-cp310-abi3-win_amd64.whl.metadata (541 bytes)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (68.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.16.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow-intel==2.15.0->tensorflow)\n",
      "  Obtaining dependency information for termcolor>=1.1.0 from https://files.pythonhosted.org/packages/d9/5f/8c716e47b3a50cbd7c146f45881e11d9414def768b7cd9c5e6650ec2a80a/termcolor-2.4.0-py3-none-any.whl.metadata\n",
      "  Downloading termcolor-2.4.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\dinak\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (4.9.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.14.1)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow-intel==2.15.0->tensorflow)\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.31.0-cp311-cp311-win_amd64.whl (1.5 MB)\n",
      "     ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "     ---------- ----------------------------- 0.4/1.5 MB 12.2 MB/s eta 0:00:01\n",
      "     ----------------------- ---------------- 0.9/1.5 MB 11.2 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 1.3/1.5 MB 10.6 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 1.5/1.5 MB 8.6 MB/s eta 0:00:00\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow-intel==2.15.0->tensorflow)\n",
      "  Obtaining dependency information for grpcio<2.0,>=1.24.3 from https://files.pythonhosted.org/packages/7b/3e/a22e7a0ec6be5454dc540063ac5d0843eb72a4641a0892b54b16b1438c0a/grpcio-1.60.1-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading grpcio-1.60.1-cp311-cp311-win_amd64.whl.metadata (4.2 kB)\n",
      "Collecting tensorboard<2.16,>=2.15 (from tensorflow-intel==2.15.0->tensorflow)\n",
      "  Obtaining dependency information for tensorboard<2.16,>=2.15 from https://files.pythonhosted.org/packages/6e/0c/1059a6682cf2cc1fcc0d5327837b5672fe4f5574255fa5430d0a8ceb75e9/tensorboard-2.15.1-py3-none-any.whl.metadata\n",
      "  Downloading tensorboard-2.15.1-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting tensorflow-estimator<2.16,>=2.15.0 (from tensorflow-intel==2.15.0->tensorflow)\n",
      "  Obtaining dependency information for tensorflow-estimator<2.16,>=2.15.0 from https://files.pythonhosted.org/packages/b6/c8/2f823c8958d5342eafc6dd3e922f0cc4fcf8c2e0460284cc462dae3b60a0/tensorflow_estimator-2.15.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading tensorflow_estimator-2.15.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting keras<2.16,>=2.15.0 (from tensorflow-intel==2.15.0->tensorflow)\n",
      "  Obtaining dependency information for keras<2.16,>=2.15.0 from https://files.pythonhosted.org/packages/fc/a7/0d4490de967a67f68a538cc9cdb259bff971c4b5787f7765dc7c8f118f71/keras-2.15.0-py3-none-any.whl.metadata\n",
      "  Downloading keras-2.15.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.15.0->tensorflow) (0.38.4)\n",
      "Collecting google-auth<3,>=1.6.3 (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow)\n",
      "  Obtaining dependency information for google-auth<3,>=1.6.3 from https://files.pythonhosted.org/packages/82/41/7fb855444cead5b2213e053447ce3a0b7bf2c3529c443e0cf75b2f13b405/google_auth-2.27.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading google_auth-2.27.0-py2.py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting google-auth-oauthlib<2,>=0.5 (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow)\n",
      "  Obtaining dependency information for google-auth-oauthlib<2,>=0.5 from https://files.pythonhosted.org/packages/71/bf/9e125754d1adb3bc4bd206c4e5df756513b1d23675ac06caa471278d1f3f/google_auth_oauthlib-1.2.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading google_auth_oauthlib-1.2.0-py2.py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.4.1)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 (from tensorflow-intel==2.15.0->tensorflow)\n",
      "  Obtaining dependency information for protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 from https://files.pythonhosted.org/packages/80/70/dc63d340d27b8ff22022d7dd14b8d6d68b479a003eacdc4507150a286d9a/protobuf-4.23.4-cp310-abi3-win_amd64.whl.metadata\n",
      "  Downloading protobuf-4.23.4-cp310-abi3-win_amd64.whl.metadata (540 bytes)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.31.0)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow)\n",
      "  Obtaining dependency information for tensorboard-data-server<0.8.0,>=0.7.0 from https://files.pythonhosted.org/packages/7a/13/e503968fefabd4c6b2650af21e110aa8466fe21432cd7c43a84577a89438/tensorboard_data_server-0.7.2-py3-none-any.whl.metadata\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.2.3)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow)\n",
      "  Obtaining dependency information for cachetools<6.0,>=2.0.0 from https://files.pythonhosted.org/packages/a2/91/2d843adb9fbd911e0da45fbf6f18ca89d07a087c3daa23e955584f90ebf4/cachetools-5.3.2-py3-none-any.whl.metadata\n",
      "  Downloading cachetools-5.3.2-py3-none-any.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.2.8)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow)\n",
      "  Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Collecting requests-oauthlib>=0.7.0 (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow)\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.4.8)\n",
      "Collecting oauthlib>=3.0.0 (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow)\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "     ---------------------------------------- 0.0/151.7 kB ? eta -:--:--\n",
      "     -------------------------------------- 151.7/151.7 kB 8.8 MB/s eta 0:00:00\n",
      "Downloading tensorflow-2.15.0-cp311-cp311-win_amd64.whl (2.1 kB)\n",
      "Downloading tensorflow_intel-2.15.0-cp311-cp311-win_amd64.whl (300.9 MB)\n",
      "   ---------------------------------------- 0.0/300.9 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.4/300.9 MB 11.8 MB/s eta 0:00:26\n",
      "   ---------------------------------------- 0.7/300.9 MB 8.3 MB/s eta 0:00:37\n",
      "   ---------------------------------------- 1.1/300.9 MB 8.5 MB/s eta 0:00:36\n",
      "   ---------------------------------------- 1.5/300.9 MB 8.5 MB/s eta 0:00:36\n",
      "   ---------------------------------------- 1.8/300.9 MB 8.3 MB/s eta 0:00:36\n",
      "   ---------------------------------------- 2.3/300.9 MB 8.7 MB/s eta 0:00:35\n",
      "   ---------------------------------------- 2.7/300.9 MB 8.6 MB/s eta 0:00:35\n",
      "   ---------------------------------------- 3.0/300.9 MB 8.3 MB/s eta 0:00:36\n",
      "   ---------------------------------------- 3.4/300.9 MB 8.2 MB/s eta 0:00:37\n",
      "   ---------------------------------------- 3.6/300.9 MB 8.0 MB/s eta 0:00:38\n",
      "    --------------------------------------- 4.1/300.9 MB 8.2 MB/s eta 0:00:37\n",
      "    --------------------------------------- 4.5/300.9 MB 8.2 MB/s eta 0:00:37\n",
      "    --------------------------------------- 4.9/300.9 MB 8.3 MB/s eta 0:00:36\n",
      "    --------------------------------------- 5.4/300.9 MB 8.4 MB/s eta 0:00:36\n",
      "    --------------------------------------- 5.9/300.9 MB 8.5 MB/s eta 0:00:35\n",
      "    --------------------------------------- 6.0/300.9 MB 8.6 MB/s eta 0:00:35\n",
      "    --------------------------------------- 6.1/300.9 MB 7.8 MB/s eta 0:00:38\n",
      "    --------------------------------------- 6.5/300.9 MB 7.8 MB/s eta 0:00:38\n",
      "    --------------------------------------- 6.7/300.9 MB 7.7 MB/s eta 0:00:39\n",
      "    --------------------------------------- 7.1/300.9 MB 7.8 MB/s eta 0:00:38\n",
      "    --------------------------------------- 7.3/300.9 MB 7.7 MB/s eta 0:00:39\n",
      "   - -------------------------------------- 7.6/300.9 MB 7.6 MB/s eta 0:00:39\n",
      "   - -------------------------------------- 8.0/300.9 MB 7.5 MB/s eta 0:00:39\n",
      "   - -------------------------------------- 8.3/300.9 MB 7.6 MB/s eta 0:00:39\n",
      "   - -------------------------------------- 8.6/300.9 MB 7.5 MB/s eta 0:00:39\n",
      "   - -------------------------------------- 8.9/300.9 MB 7.5 MB/s eta 0:00:39\n",
      "   - -------------------------------------- 9.2/300.9 MB 7.5 MB/s eta 0:00:40\n",
      "   - -------------------------------------- 9.6/300.9 MB 7.5 MB/s eta 0:00:40\n",
      "   - -------------------------------------- 9.8/300.9 MB 7.4 MB/s eta 0:00:40\n",
      "   - -------------------------------------- 10.1/300.9 MB 7.3 MB/s eta 0:00:40\n",
      "   - -------------------------------------- 10.5/300.9 MB 7.3 MB/s eta 0:00:40\n",
      "   - -------------------------------------- 10.9/300.9 MB 7.4 MB/s eta 0:00:40\n",
      "   - -------------------------------------- 11.4/300.9 MB 7.4 MB/s eta 0:00:40\n",
      "   - -------------------------------------- 11.8/300.9 MB 7.4 MB/s eta 0:00:39\n",
      "   - -------------------------------------- 12.2/300.9 MB 7.4 MB/s eta 0:00:39\n",
      "   - -------------------------------------- 12.7/300.9 MB 7.4 MB/s eta 0:00:39\n",
      "   - -------------------------------------- 13.1/300.9 MB 7.5 MB/s eta 0:00:39\n",
      "   - -------------------------------------- 13.4/300.9 MB 7.4 MB/s eta 0:00:40\n",
      "   - -------------------------------------- 13.8/300.9 MB 7.4 MB/s eta 0:00:39\n",
      "   - -------------------------------------- 14.2/300.9 MB 7.5 MB/s eta 0:00:39\n",
      "   - -------------------------------------- 14.7/300.9 MB 7.4 MB/s eta 0:00:39\n",
      "   -- ------------------------------------- 15.1/300.9 MB 7.4 MB/s eta 0:00:39\n",
      "   -- ------------------------------------- 15.6/300.9 MB 7.5 MB/s eta 0:00:38\n",
      "   -- ------------------------------------- 16.0/300.9 MB 7.5 MB/s eta 0:00:38\n",
      "   -- ------------------------------------- 16.4/300.9 MB 7.9 MB/s eta 0:00:37\n",
      "   -- ------------------------------------- 16.8/300.9 MB 7.9 MB/s eta 0:00:36\n",
      "   -- ------------------------------------- 17.1/300.9 MB 8.0 MB/s eta 0:00:36\n",
      "   -- ------------------------------------- 17.4/300.9 MB 8.0 MB/s eta 0:00:36\n",
      "   -- ------------------------------------- 17.8/300.9 MB 8.1 MB/s eta 0:00:36\n",
      "   -- ------------------------------------- 18.0/300.9 MB 8.0 MB/s eta 0:00:36\n",
      "   -- ------------------------------------- 18.3/300.9 MB 7.9 MB/s eta 0:00:36\n",
      "   -- ------------------------------------- 18.5/300.9 MB 7.8 MB/s eta 0:00:37\n",
      "   -- ------------------------------------- 18.7/300.9 MB 7.7 MB/s eta 0:00:37\n",
      "   -- ------------------------------------- 19.0/300.9 MB 7.7 MB/s eta 0:00:37\n",
      "   -- ------------------------------------- 19.2/300.9 MB 7.6 MB/s eta 0:00:37\n",
      "   -- ------------------------------------- 19.4/300.9 MB 7.5 MB/s eta 0:00:38\n",
      "   -- ------------------------------------- 19.7/300.9 MB 7.5 MB/s eta 0:00:38\n",
      "   -- ------------------------------------- 20.0/300.9 MB 7.5 MB/s eta 0:00:38\n",
      "   -- ------------------------------------- 20.4/300.9 MB 7.6 MB/s eta 0:00:37\n",
      "   -- ------------------------------------- 20.8/300.9 MB 7.6 MB/s eta 0:00:37\n",
      "   -- ------------------------------------- 21.2/300.9 MB 7.6 MB/s eta 0:00:37\n",
      "   -- ------------------------------------- 21.5/300.9 MB 7.5 MB/s eta 0:00:38\n",
      "   -- ------------------------------------- 21.9/300.9 MB 7.4 MB/s eta 0:00:38\n",
      "   -- ------------------------------------- 22.1/300.9 MB 7.4 MB/s eta 0:00:38\n",
      "   -- ------------------------------------- 22.5/300.9 MB 7.4 MB/s eta 0:00:38\n",
      "   --- ------------------------------------ 22.9/300.9 MB 7.3 MB/s eta 0:00:39\n",
      "   --- ------------------------------------ 23.2/300.9 MB 7.3 MB/s eta 0:00:39\n",
      "   --- ------------------------------------ 23.5/300.9 MB 7.3 MB/s eta 0:00:39\n",
      "   --- ------------------------------------ 23.9/300.9 MB 7.3 MB/s eta 0:00:39\n",
      "   --- ------------------------------------ 24.3/300.9 MB 7.3 MB/s eta 0:00:39\n",
      "   --- ------------------------------------ 24.7/300.9 MB 7.2 MB/s eta 0:00:39\n",
      "   --- ------------------------------------ 25.0/300.9 MB 7.1 MB/s eta 0:00:39\n",
      "   --- ------------------------------------ 25.4/300.9 MB 7.1 MB/s eta 0:00:39\n",
      "   --- ------------------------------------ 25.8/300.9 MB 7.0 MB/s eta 0:00:40\n",
      "   --- ------------------------------------ 26.1/300.9 MB 7.0 MB/s eta 0:00:40\n",
      "   --- ------------------------------------ 26.5/300.9 MB 7.0 MB/s eta 0:00:40\n",
      "   --- ------------------------------------ 26.8/300.9 MB 7.0 MB/s eta 0:00:40\n",
      "   --- ------------------------------------ 27.1/300.9 MB 7.0 MB/s eta 0:00:40\n",
      "   --- ------------------------------------ 27.5/300.9 MB 7.0 MB/s eta 0:00:40\n",
      "   --- ------------------------------------ 27.7/300.9 MB 6.9 MB/s eta 0:00:40\n",
      "   --- ------------------------------------ 28.1/300.9 MB 6.9 MB/s eta 0:00:40\n",
      "   --- ------------------------------------ 28.4/300.9 MB 7.0 MB/s eta 0:00:39\n",
      "   --- ------------------------------------ 28.7/300.9 MB 7.0 MB/s eta 0:00:39\n",
      "   --- ------------------------------------ 29.1/300.9 MB 7.1 MB/s eta 0:00:39\n",
      "   --- ------------------------------------ 29.4/300.9 MB 7.3 MB/s eta 0:00:38\n",
      "   --- ------------------------------------ 29.6/300.9 MB 7.3 MB/s eta 0:00:38\n",
      "   --- ------------------------------------ 30.0/300.9 MB 7.4 MB/s eta 0:00:37\n",
      "   ---- ----------------------------------- 30.2/300.9 MB 7.3 MB/s eta 0:00:38\n",
      "   ---- ----------------------------------- 30.6/300.9 MB 7.3 MB/s eta 0:00:38\n",
      "   ---- ----------------------------------- 30.9/300.9 MB 7.2 MB/s eta 0:00:38\n",
      "   ---- ----------------------------------- 31.0/300.9 MB 7.0 MB/s eta 0:00:39\n",
      "   ---- ----------------------------------- 31.1/300.9 MB 7.0 MB/s eta 0:00:39\n",
      "   ---- ----------------------------------- 31.2/300.9 MB 6.7 MB/s eta 0:00:41\n",
      "   ---- ----------------------------------- 31.3/300.9 MB 6.5 MB/s eta 0:00:42\n",
      "   ---- ----------------------------------- 31.4/300.9 MB 6.5 MB/s eta 0:00:42\n",
      "   ---- ----------------------------------- 31.5/300.9 MB 6.3 MB/s eta 0:00:43\n",
      "   ---- ----------------------------------- 31.9/300.9 MB 6.3 MB/s eta 0:00:43\n",
      "   ---- ----------------------------------- 32.1/300.9 MB 6.2 MB/s eta 0:00:44\n",
      "   ---- ----------------------------------- 32.4/300.9 MB 6.2 MB/s eta 0:00:44\n",
      "   ---- ----------------------------------- 32.8/300.9 MB 6.3 MB/s eta 0:00:43\n",
      "   ---- ----------------------------------- 33.2/300.9 MB 6.3 MB/s eta 0:00:43\n",
      "   ---- ----------------------------------- 33.5/300.9 MB 6.3 MB/s eta 0:00:43\n",
      "   ---- ----------------------------------- 33.9/300.9 MB 6.3 MB/s eta 0:00:43\n",
      "   ---- ----------------------------------- 34.3/300.9 MB 6.3 MB/s eta 0:00:43\n",
      "   ---- ----------------------------------- 34.7/300.9 MB 6.3 MB/s eta 0:00:43\n",
      "   ---- ----------------------------------- 35.0/300.9 MB 6.3 MB/s eta 0:00:43\n",
      "   ---- ----------------------------------- 35.4/300.9 MB 6.4 MB/s eta 0:00:42\n",
      "   ---- ----------------------------------- 35.8/300.9 MB 6.4 MB/s eta 0:00:42\n",
      "   ---- ----------------------------------- 36.1/300.9 MB 6.4 MB/s eta 0:00:42\n",
      "   ---- ----------------------------------- 36.5/300.9 MB 6.3 MB/s eta 0:00:43\n",
      "   ---- ----------------------------------- 36.9/300.9 MB 6.3 MB/s eta 0:00:42\n",
      "   ---- ----------------------------------- 37.2/300.9 MB 6.4 MB/s eta 0:00:42\n",
      "   ---- ----------------------------------- 37.5/300.9 MB 6.4 MB/s eta 0:00:42\n",
      "   ----- ---------------------------------- 37.9/300.9 MB 6.4 MB/s eta 0:00:42\n",
      "   ----- ---------------------------------- 38.3/300.9 MB 6.5 MB/s eta 0:00:41\n",
      "   ----- ---------------------------------- 38.7/300.9 MB 6.5 MB/s eta 0:00:41\n",
      "   ----- ---------------------------------- 39.0/300.9 MB 6.5 MB/s eta 0:00:41\n",
      "   ----- ---------------------------------- 39.3/300.9 MB 6.5 MB/s eta 0:00:40\n",
      "   ----- ---------------------------------- 39.7/300.9 MB 6.6 MB/s eta 0:00:40\n",
      "   ----- ---------------------------------- 40.1/300.9 MB 6.6 MB/s eta 0:00:40\n",
      "   ----- ---------------------------------- 40.5/300.9 MB 6.7 MB/s eta 0:00:39\n",
      "   ----- ---------------------------------- 40.8/300.9 MB 6.7 MB/s eta 0:00:39\n",
      "   ----- ---------------------------------- 41.1/300.9 MB 6.7 MB/s eta 0:00:39\n",
      "   ----- ---------------------------------- 41.5/300.9 MB 7.4 MB/s eta 0:00:36\n",
      "   ----- ---------------------------------- 41.9/300.9 MB 7.7 MB/s eta 0:00:34\n",
      "   ----- ---------------------------------- 42.2/300.9 MB 7.8 MB/s eta 0:00:34\n",
      "   ----- ---------------------------------- 42.6/300.9 MB 7.8 MB/s eta 0:00:34\n",
      "   ----- ---------------------------------- 43.0/300.9 MB 7.8 MB/s eta 0:00:34\n",
      "   ----- ---------------------------------- 43.4/300.9 MB 7.9 MB/s eta 0:00:33\n",
      "   ----- ---------------------------------- 43.7/300.9 MB 7.8 MB/s eta 0:00:33\n",
      "   ----- ---------------------------------- 44.1/300.9 MB 7.9 MB/s eta 0:00:33\n",
      "   ----- ---------------------------------- 44.5/300.9 MB 7.8 MB/s eta 0:00:33\n",
      "   ----- ---------------------------------- 44.8/300.9 MB 7.8 MB/s eta 0:00:33\n",
      "   ------ --------------------------------- 45.3/300.9 MB 7.9 MB/s eta 0:00:33\n",
      "   ------ --------------------------------- 45.6/300.9 MB 7.9 MB/s eta 0:00:33\n",
      "   ------ --------------------------------- 46.0/300.9 MB 7.8 MB/s eta 0:00:33\n",
      "   ------ --------------------------------- 46.4/300.9 MB 7.9 MB/s eta 0:00:33\n",
      "   ------ --------------------------------- 46.8/300.9 MB 7.9 MB/s eta 0:00:33\n",
      "   ------ --------------------------------- 47.1/300.9 MB 7.9 MB/s eta 0:00:33\n",
      "   ------ --------------------------------- 47.5/300.9 MB 8.0 MB/s eta 0:00:32\n",
      "   ------ --------------------------------- 47.8/300.9 MB 8.0 MB/s eta 0:00:32\n",
      "   ------ --------------------------------- 48.2/300.9 MB 7.9 MB/s eta 0:00:33\n",
      "   ------ --------------------------------- 48.5/300.9 MB 7.8 MB/s eta 0:00:33\n",
      "   ------ --------------------------------- 48.9/300.9 MB 7.9 MB/s eta 0:00:32\n",
      "   ------ --------------------------------- 49.1/300.9 MB 7.8 MB/s eta 0:00:33\n",
      "   ------ --------------------------------- 49.6/300.9 MB 7.9 MB/s eta 0:00:32\n",
      "   ------ --------------------------------- 49.9/300.9 MB 7.9 MB/s eta 0:00:32\n",
      "   ------ --------------------------------- 50.3/300.9 MB 7.9 MB/s eta 0:00:32\n",
      "   ------ --------------------------------- 50.7/300.9 MB 8.0 MB/s eta 0:00:32\n",
      "   ------ --------------------------------- 51.0/300.9 MB 7.9 MB/s eta 0:00:32\n",
      "   ------ --------------------------------- 51.3/300.9 MB 7.9 MB/s eta 0:00:32\n",
      "   ------ --------------------------------- 51.6/300.9 MB 7.8 MB/s eta 0:00:33\n",
      "   ------ --------------------------------- 52.0/300.9 MB 7.9 MB/s eta 0:00:32\n",
      "   ------ --------------------------------- 52.4/300.9 MB 7.9 MB/s eta 0:00:32\n",
      "   ------- -------------------------------- 52.8/300.9 MB 7.9 MB/s eta 0:00:32\n",
      "   ------- -------------------------------- 53.2/300.9 MB 8.0 MB/s eta 0:00:32\n",
      "   ------- -------------------------------- 53.6/300.9 MB 8.0 MB/s eta 0:00:31\n",
      "   ------- -------------------------------- 54.0/300.9 MB 8.0 MB/s eta 0:00:31\n",
      "   ------- -------------------------------- 54.4/300.9 MB 8.0 MB/s eta 0:00:31\n",
      "   ------- -------------------------------- 54.9/300.9 MB 8.1 MB/s eta 0:00:31\n",
      "   ------- -------------------------------- 55.3/300.9 MB 8.0 MB/s eta 0:00:31\n",
      "   ------- -------------------------------- 55.7/300.9 MB 8.0 MB/s eta 0:00:31\n",
      "   ------- -------------------------------- 56.0/300.9 MB 8.0 MB/s eta 0:00:31\n",
      "   ------- -------------------------------- 56.4/300.9 MB 8.1 MB/s eta 0:00:31\n",
      "   ------- -------------------------------- 56.8/300.9 MB 8.0 MB/s eta 0:00:31\n",
      "   ------- -------------------------------- 57.1/300.9 MB 8.1 MB/s eta 0:00:31\n",
      "   ------- -------------------------------- 57.5/300.9 MB 8.0 MB/s eta 0:00:31\n",
      "   ------- -------------------------------- 57.8/300.9 MB 8.1 MB/s eta 0:00:31\n",
      "   ------- -------------------------------- 58.2/300.9 MB 8.1 MB/s eta 0:00:31\n",
      "   ------- -------------------------------- 58.6/300.9 MB 8.1 MB/s eta 0:00:30\n",
      "   ------- -------------------------------- 59.0/300.9 MB 8.1 MB/s eta 0:00:30\n",
      "   ------- -------------------------------- 59.4/300.9 MB 8.2 MB/s eta 0:00:30\n",
      "   ------- -------------------------------- 59.8/300.9 MB 8.2 MB/s eta 0:00:30\n",
      "   ------- -------------------------------- 60.2/300.9 MB 8.3 MB/s eta 0:00:30\n",
      "   -------- ------------------------------- 60.6/300.9 MB 8.3 MB/s eta 0:00:29\n",
      "   -------- ------------------------------- 61.0/300.9 MB 8.3 MB/s eta 0:00:29\n",
      "   -------- ------------------------------- 61.4/300.9 MB 8.4 MB/s eta 0:00:29\n",
      "   -------- ------------------------------- 61.8/300.9 MB 8.6 MB/s eta 0:00:28\n",
      "   -------- ------------------------------- 62.2/300.9 MB 8.5 MB/s eta 0:00:29\n",
      "   -------- ------------------------------- 62.7/300.9 MB 8.6 MB/s eta 0:00:28\n",
      "   -------- ------------------------------- 62.9/300.9 MB 8.5 MB/s eta 0:00:28\n",
      "   -------- ------------------------------- 63.3/300.9 MB 8.4 MB/s eta 0:00:29\n",
      "   -------- ------------------------------- 63.7/300.9 MB 8.4 MB/s eta 0:00:29\n",
      "   -------- ------------------------------- 64.1/300.9 MB 8.4 MB/s eta 0:00:29\n",
      "   -------- ------------------------------- 64.6/300.9 MB 8.4 MB/s eta 0:00:29\n",
      "   -------- ------------------------------- 65.0/300.9 MB 8.4 MB/s eta 0:00:29\n",
      "   -------- ------------------------------- 65.4/300.9 MB 8.4 MB/s eta 0:00:29\n",
      "   -------- ------------------------------- 65.9/300.9 MB 8.5 MB/s eta 0:00:28\n",
      "   -------- ------------------------------- 66.3/300.9 MB 8.5 MB/s eta 0:00:28\n",
      "   -------- ------------------------------- 66.6/300.9 MB 8.5 MB/s eta 0:00:28\n",
      "   -------- ------------------------------- 67.0/300.9 MB 8.5 MB/s eta 0:00:28\n",
      "   -------- ------------------------------- 67.4/300.9 MB 8.5 MB/s eta 0:00:28\n",
      "   --------- ------------------------------ 67.9/300.9 MB 8.5 MB/s eta 0:00:28\n",
      "   --------- ------------------------------ 68.2/300.9 MB 8.5 MB/s eta 0:00:28\n",
      "   --------- ------------------------------ 68.6/300.9 MB 8.5 MB/s eta 0:00:28\n",
      "   --------- ------------------------------ 69.0/300.9 MB 8.6 MB/s eta 0:00:27\n",
      "   --------- ------------------------------ 69.5/300.9 MB 8.7 MB/s eta 0:00:27\n",
      "   --------- ------------------------------ 70.0/300.9 MB 8.8 MB/s eta 0:00:27\n",
      "   --------- ------------------------------ 70.5/300.9 MB 8.8 MB/s eta 0:00:27\n",
      "   --------- ------------------------------ 71.0/300.9 MB 9.0 MB/s eta 0:00:26\n",
      "   --------- ------------------------------ 71.5/300.9 MB 9.0 MB/s eta 0:00:26\n",
      "   --------- ------------------------------ 72.0/300.9 MB 9.1 MB/s eta 0:00:26\n",
      "   --------- ------------------------------ 72.5/300.9 MB 9.1 MB/s eta 0:00:26\n",
      "   --------- ------------------------------ 73.0/300.9 MB 9.4 MB/s eta 0:00:25\n",
      "   --------- ------------------------------ 73.6/300.9 MB 9.5 MB/s eta 0:00:24\n",
      "   --------- ------------------------------ 74.1/300.9 MB 9.8 MB/s eta 0:00:24\n",
      "   --------- ------------------------------ 74.6/300.9 MB 9.8 MB/s eta 0:00:24\n",
      "   --------- ------------------------------ 75.0/300.9 MB 9.8 MB/s eta 0:00:24\n",
      "   ---------- ----------------------------- 75.3/300.9 MB 9.6 MB/s eta 0:00:24\n",
      "   ---------- ----------------------------- 75.8/300.9 MB 9.8 MB/s eta 0:00:24\n",
      "   ---------- ----------------------------- 76.3/300.9 MB 9.9 MB/s eta 0:00:23\n",
      "   ---------- ----------------------------- 76.8/300.9 MB 10.1 MB/s eta 0:00:23\n",
      "   ---------- ----------------------------- 77.4/300.9 MB 10.2 MB/s eta 0:00:22\n",
      "   ---------- ----------------------------- 77.7/300.9 MB 10.2 MB/s eta 0:00:22\n",
      "   ---------- ----------------------------- 78.3/300.9 MB 10.2 MB/s eta 0:00:22\n",
      "   ---------- ----------------------------- 78.8/300.9 MB 10.6 MB/s eta 0:00:22\n",
      "   ---------- ----------------------------- 79.3/300.9 MB 10.7 MB/s eta 0:00:21\n",
      "   ---------- ----------------------------- 79.9/300.9 MB 10.7 MB/s eta 0:00:21\n",
      "   ---------- ----------------------------- 80.4/300.9 MB 10.7 MB/s eta 0:00:21\n",
      "   ---------- ----------------------------- 80.9/300.9 MB 10.7 MB/s eta 0:00:21\n",
      "   ---------- ----------------------------- 81.4/300.9 MB 10.7 MB/s eta 0:00:21\n",
      "   ---------- ----------------------------- 81.8/300.9 MB 10.7 MB/s eta 0:00:21\n",
      "   ---------- ----------------------------- 82.2/300.9 MB 10.6 MB/s eta 0:00:21\n",
      "   ----------- ---------------------------- 82.8/300.9 MB 10.7 MB/s eta 0:00:21\n",
      "   ----------- ---------------------------- 83.0/300.9 MB 10.4 MB/s eta 0:00:21\n",
      "   ----------- ---------------------------- 83.6/300.9 MB 10.6 MB/s eta 0:00:21\n",
      "   ----------- ---------------------------- 84.1/300.9 MB 10.4 MB/s eta 0:00:21\n",
      "   ----------- ---------------------------- 84.4/300.9 MB 10.2 MB/s eta 0:00:22\n",
      "   ----------- ---------------------------- 84.8/300.9 MB 10.1 MB/s eta 0:00:22\n",
      "   ----------- ---------------------------- 85.3/300.9 MB 10.2 MB/s eta 0:00:22\n",
      "   ----------- ---------------------------- 85.8/300.9 MB 10.4 MB/s eta 0:00:21\n",
      "   ----------- ---------------------------- 86.3/300.9 MB 10.4 MB/s eta 0:00:21\n",
      "   ----------- ---------------------------- 86.8/300.9 MB 10.4 MB/s eta 0:00:21\n",
      "   ----------- ---------------------------- 87.4/300.9 MB 10.4 MB/s eta 0:00:21\n",
      "   ----------- ---------------------------- 87.9/300.9 MB 10.6 MB/s eta 0:00:21\n",
      "   ----------- ---------------------------- 88.4/300.9 MB 10.4 MB/s eta 0:00:21\n",
      "   ----------- ---------------------------- 89.0/300.9 MB 10.6 MB/s eta 0:00:21\n",
      "   ----------- ---------------------------- 89.3/300.9 MB 10.2 MB/s eta 0:00:21\n",
      "   ----------- ---------------------------- 89.7/300.9 MB 10.1 MB/s eta 0:00:21\n",
      "   ----------- ---------------------------- 90.1/300.9 MB 10.1 MB/s eta 0:00:21\n",
      "   ------------ --------------------------- 90.6/300.9 MB 10.1 MB/s eta 0:00:21\n",
      "   ------------ --------------------------- 91.2/300.9 MB 10.1 MB/s eta 0:00:21\n",
      "   ------------ --------------------------- 91.7/300.9 MB 10.1 MB/s eta 0:00:21\n",
      "   ------------ --------------------------- 92.3/300.9 MB 10.2 MB/s eta 0:00:21\n",
      "   ------------ --------------------------- 92.8/300.9 MB 10.2 MB/s eta 0:00:21\n",
      "   ------------ --------------------------- 93.4/300.9 MB 10.6 MB/s eta 0:00:20\n",
      "   ------------ --------------------------- 93.8/300.9 MB 10.7 MB/s eta 0:00:20\n",
      "   ------------ --------------------------- 94.4/300.9 MB 10.6 MB/s eta 0:00:20\n",
      "   ------------ --------------------------- 94.9/300.9 MB 10.7 MB/s eta 0:00:20\n",
      "   ------------ --------------------------- 95.4/300.9 MB 11.1 MB/s eta 0:00:19\n",
      "   ------------ --------------------------- 95.9/300.9 MB 10.9 MB/s eta 0:00:19\n",
      "   ------------ --------------------------- 96.2/300.9 MB 10.9 MB/s eta 0:00:19\n",
      "   ------------ --------------------------- 96.7/300.9 MB 10.7 MB/s eta 0:00:20\n",
      "   ------------ --------------------------- 97.0/300.9 MB 10.6 MB/s eta 0:00:20\n",
      "   ------------ --------------------------- 97.4/300.9 MB 10.6 MB/s eta 0:00:20\n",
      "   ------------- -------------------------- 98.0/300.9 MB 10.4 MB/s eta 0:00:20\n",
      "   ------------- -------------------------- 98.4/300.9 MB 10.2 MB/s eta 0:00:20\n",
      "   ------------- -------------------------- 98.8/300.9 MB 10.2 MB/s eta 0:00:20\n",
      "   ------------- -------------------------- 99.3/300.9 MB 10.1 MB/s eta 0:00:21\n",
      "   ------------- -------------------------- 99.6/300.9 MB 10.2 MB/s eta 0:00:20\n",
      "   ------------ -------------------------- 100.1/300.9 MB 10.4 MB/s eta 0:00:20\n",
      "   ------------- ------------------------- 100.6/300.9 MB 10.4 MB/s eta 0:00:20\n",
      "   ------------- ------------------------- 101.0/300.9 MB 10.2 MB/s eta 0:00:20\n",
      "   ------------- ------------------------- 101.4/300.9 MB 10.1 MB/s eta 0:00:20\n",
      "   ------------- ------------------------- 101.9/300.9 MB 10.1 MB/s eta 0:00:20\n",
      "   ------------- -------------------------- 102.3/300.9 MB 9.9 MB/s eta 0:00:21\n",
      "   ------------- -------------------------- 102.8/300.9 MB 9.8 MB/s eta 0:00:21\n",
      "   ------------- -------------------------- 103.3/300.9 MB 9.9 MB/s eta 0:00:20\n",
      "   ------------- -------------------------- 103.3/300.9 MB 9.4 MB/s eta 0:00:22\n",
      "   ------------- -------------------------- 103.7/300.9 MB 9.2 MB/s eta 0:00:22\n",
      "   ------------- -------------------------- 104.2/300.9 MB 9.2 MB/s eta 0:00:22\n",
      "   ------------- -------------------------- 104.6/300.9 MB 9.2 MB/s eta 0:00:22\n",
      "   ------------- -------------------------- 105.0/300.9 MB 9.0 MB/s eta 0:00:22\n",
      "   ------------- -------------------------- 105.3/300.9 MB 9.0 MB/s eta 0:00:22\n",
      "   -------------- ------------------------- 105.8/300.9 MB 9.1 MB/s eta 0:00:22\n",
      "   -------------- ------------------------- 106.2/300.9 MB 8.8 MB/s eta 0:00:23\n",
      "   -------------- ------------------------- 106.6/300.9 MB 9.0 MB/s eta 0:00:22\n",
      "   -------------- ------------------------- 107.1/300.9 MB 9.1 MB/s eta 0:00:22\n",
      "   -------------- ------------------------- 107.5/300.9 MB 9.1 MB/s eta 0:00:22\n",
      "   -------------- ------------------------- 107.6/300.9 MB 9.1 MB/s eta 0:00:22\n",
      "   -------------- ------------------------- 107.8/300.9 MB 8.6 MB/s eta 0:00:23\n",
      "   -------------- ------------------------- 108.2/300.9 MB 8.5 MB/s eta 0:00:23\n",
      "   -------------- ------------------------- 108.7/300.9 MB 8.6 MB/s eta 0:00:23\n",
      "   -------------- ------------------------- 109.2/300.9 MB 8.6 MB/s eta 0:00:23\n",
      "   -------------- ------------------------- 109.4/300.9 MB 8.4 MB/s eta 0:00:23\n",
      "   -------------- ------------------------- 109.5/300.9 MB 8.2 MB/s eta 0:00:24\n",
      "   -------------- ------------------------- 109.6/300.9 MB 8.0 MB/s eta 0:00:24\n",
      "   -------------- ------------------------- 109.7/300.9 MB 7.7 MB/s eta 0:00:25\n",
      "   -------------- ------------------------- 109.9/300.9 MB 7.8 MB/s eta 0:00:25\n",
      "   -------------- ------------------------- 110.1/300.9 MB 7.4 MB/s eta 0:00:26\n",
      "   -------------- ------------------------- 110.4/300.9 MB 7.4 MB/s eta 0:00:26\n",
      "   -------------- ------------------------- 110.8/300.9 MB 7.3 MB/s eta 0:00:27\n",
      "   -------------- ------------------------- 110.9/300.9 MB 7.2 MB/s eta 0:00:27\n",
      "   -------------- ------------------------- 111.4/300.9 MB 7.2 MB/s eta 0:00:27\n",
      "   -------------- ------------------------- 111.9/300.9 MB 7.2 MB/s eta 0:00:27\n",
      "   -------------- ------------------------- 112.4/300.9 MB 7.3 MB/s eta 0:00:26\n",
      "   --------------- ------------------------ 113.0/300.9 MB 7.4 MB/s eta 0:00:26\n",
      "   --------------- ------------------------ 113.5/300.9 MB 7.6 MB/s eta 0:00:25\n",
      "   --------------- ------------------------ 114.1/300.9 MB 7.7 MB/s eta 0:00:25\n",
      "   --------------- ------------------------ 114.4/300.9 MB 7.6 MB/s eta 0:00:25\n",
      "   --------------- ------------------------ 115.0/300.9 MB 7.7 MB/s eta 0:00:25\n",
      "   --------------- ------------------------ 115.5/300.9 MB 7.9 MB/s eta 0:00:24\n",
      "   --------------- ------------------------ 116.1/300.9 MB 8.0 MB/s eta 0:00:24\n",
      "   --------------- ------------------------ 116.6/300.9 MB 8.1 MB/s eta 0:00:23\n",
      "   --------------- ------------------------ 117.1/300.9 MB 8.2 MB/s eta 0:00:23\n",
      "   --------------- ------------------------ 117.6/300.9 MB 8.1 MB/s eta 0:00:23\n",
      "   --------------- ------------------------ 118.1/300.9 MB 8.6 MB/s eta 0:00:22\n",
      "   --------------- ------------------------ 118.7/300.9 MB 8.7 MB/s eta 0:00:21\n",
      "   --------------- ------------------------ 119.2/300.9 MB 8.7 MB/s eta 0:00:21\n",
      "   --------------- ------------------------ 119.8/300.9 MB 9.5 MB/s eta 0:00:20\n",
      "   --------------- ----------------------- 120.2/300.9 MB 10.4 MB/s eta 0:00:18\n",
      "   --------------- ----------------------- 120.7/300.9 MB 10.6 MB/s eta 0:00:18\n",
      "   --------------- ----------------------- 121.1/300.9 MB 11.1 MB/s eta 0:00:17\n",
      "   --------------- ----------------------- 121.5/300.9 MB 11.1 MB/s eta 0:00:17\n",
      "   --------------- ----------------------- 122.1/300.9 MB 10.9 MB/s eta 0:00:17\n",
      "   --------------- ----------------------- 122.5/300.9 MB 10.9 MB/s eta 0:00:17\n",
      "   --------------- ----------------------- 123.1/300.9 MB 11.1 MB/s eta 0:00:17\n",
      "   ---------------- ---------------------- 123.5/300.9 MB 11.1 MB/s eta 0:00:16\n",
      "   ---------------- ---------------------- 124.0/300.9 MB 10.9 MB/s eta 0:00:17\n",
      "   ---------------- ---------------------- 124.5/300.9 MB 11.1 MB/s eta 0:00:16\n",
      "   ---------------- ---------------------- 125.0/300.9 MB 11.1 MB/s eta 0:00:16\n",
      "   ---------------- ---------------------- 125.5/300.9 MB 10.9 MB/s eta 0:00:17\n",
      "   ---------------- ---------------------- 126.0/300.9 MB 10.9 MB/s eta 0:00:17\n",
      "   ---------------- ---------------------- 126.6/300.9 MB 10.9 MB/s eta 0:00:16\n",
      "   ---------------- ---------------------- 127.1/300.9 MB 10.9 MB/s eta 0:00:16\n",
      "   ---------------- ---------------------- 127.6/300.9 MB 10.9 MB/s eta 0:00:16\n",
      "   ---------------- ---------------------- 128.1/300.9 MB 10.9 MB/s eta 0:00:16\n",
      "   ---------------- ---------------------- 128.7/300.9 MB 10.9 MB/s eta 0:00:16\n",
      "   ---------------- ---------------------- 129.2/300.9 MB 10.7 MB/s eta 0:00:17\n",
      "   ---------------- ---------------------- 129.7/300.9 MB 10.9 MB/s eta 0:00:16\n",
      "   ---------------- ---------------------- 130.1/300.9 MB 10.7 MB/s eta 0:00:16\n",
      "   ---------------- ---------------------- 130.6/300.9 MB 10.7 MB/s eta 0:00:16\n",
      "   ---------------- ---------------------- 131.2/300.9 MB 10.7 MB/s eta 0:00:16\n",
      "   ----------------- --------------------- 131.6/300.9 MB 10.9 MB/s eta 0:00:16\n",
      "   ----------------- --------------------- 132.0/300.9 MB 10.7 MB/s eta 0:00:16\n",
      "   ----------------- --------------------- 132.4/300.9 MB 10.7 MB/s eta 0:00:16\n",
      "   ----------------- --------------------- 132.9/300.9 MB 10.6 MB/s eta 0:00:16\n",
      "   ----------------- --------------------- 133.3/300.9 MB 10.4 MB/s eta 0:00:17\n",
      "   ----------------- --------------------- 133.7/300.9 MB 10.4 MB/s eta 0:00:17\n",
      "   ----------------- --------------------- 134.1/300.9 MB 10.2 MB/s eta 0:00:17\n",
      "   ----------------- --------------------- 134.4/300.9 MB 10.1 MB/s eta 0:00:17\n",
      "   ----------------- ---------------------- 134.7/300.9 MB 9.9 MB/s eta 0:00:17\n",
      "   ----------------- ---------------------- 135.0/300.9 MB 9.8 MB/s eta 0:00:17\n",
      "   ----------------- ---------------------- 135.3/300.9 MB 9.6 MB/s eta 0:00:18\n",
      "   ------------------ --------------------- 135.6/300.9 MB 9.4 MB/s eta 0:00:18\n",
      "   ------------------ --------------------- 136.0/300.9 MB 9.4 MB/s eta 0:00:18\n",
      "   ------------------ --------------------- 136.5/300.9 MB 9.2 MB/s eta 0:00:18\n",
      "   ------------------ --------------------- 136.9/300.9 MB 9.2 MB/s eta 0:00:18\n",
      "   ------------------ --------------------- 137.2/300.9 MB 9.1 MB/s eta 0:00:19\n",
      "   ------------------ --------------------- 137.7/300.9 MB 9.0 MB/s eta 0:00:19\n",
      "   ------------------ --------------------- 138.0/300.9 MB 8.8 MB/s eta 0:00:19\n",
      "   ------------------ --------------------- 138.4/300.9 MB 8.8 MB/s eta 0:00:19\n",
      "   ------------------ --------------------- 138.8/300.9 MB 8.8 MB/s eta 0:00:19\n",
      "   ------------------ --------------------- 139.3/300.9 MB 8.7 MB/s eta 0:00:19\n",
      "   ------------------ --------------------- 139.7/300.9 MB 8.6 MB/s eta 0:00:19\n",
      "   ------------------ --------------------- 140.1/300.9 MB 8.6 MB/s eta 0:00:19\n",
      "   ------------------ --------------------- 140.4/300.9 MB 8.5 MB/s eta 0:00:19\n",
      "   ------------------ --------------------- 140.8/300.9 MB 8.4 MB/s eta 0:00:20\n",
      "   ------------------ --------------------- 141.2/300.9 MB 8.4 MB/s eta 0:00:20\n",
      "   ------------------ --------------------- 141.6/300.9 MB 8.4 MB/s eta 0:00:19\n",
      "   ------------------ --------------------- 142.0/300.9 MB 8.4 MB/s eta 0:00:19\n",
      "   ------------------ --------------------- 142.5/300.9 MB 8.3 MB/s eta 0:00:20\n",
      "   ------------------ --------------------- 142.9/300.9 MB 8.3 MB/s eta 0:00:20\n",
      "   ------------------- -------------------- 143.4/300.9 MB 8.4 MB/s eta 0:00:19\n",
      "   ------------------- -------------------- 143.8/300.9 MB 8.4 MB/s eta 0:00:19\n",
      "   ------------------- -------------------- 144.1/300.9 MB 8.4 MB/s eta 0:00:19\n",
      "   ------------------- -------------------- 144.3/300.9 MB 8.2 MB/s eta 0:00:20\n",
      "   ------------------- -------------------- 144.7/300.9 MB 8.3 MB/s eta 0:00:19\n",
      "   ------------------- -------------------- 145.1/300.9 MB 8.3 MB/s eta 0:00:19\n",
      "   ------------------- -------------------- 145.5/300.9 MB 8.4 MB/s eta 0:00:19\n",
      "   ------------------- -------------------- 145.8/300.9 MB 8.4 MB/s eta 0:00:19\n",
      "   ------------------- -------------------- 146.2/300.9 MB 8.5 MB/s eta 0:00:19\n",
      "   ------------------- -------------------- 146.6/300.9 MB 8.4 MB/s eta 0:00:19\n",
      "   ------------------- -------------------- 146.9/300.9 MB 8.4 MB/s eta 0:00:19\n",
      "   ------------------- -------------------- 147.0/300.9 MB 8.1 MB/s eta 0:00:20\n",
      "   ------------------- -------------------- 147.2/300.9 MB 8.1 MB/s eta 0:00:20\n",
      "   ------------------- -------------------- 147.6/300.9 MB 7.9 MB/s eta 0:00:20\n",
      "   ------------------- -------------------- 147.9/300.9 MB 8.0 MB/s eta 0:00:20\n",
      "   ------------------- -------------------- 148.3/300.9 MB 8.0 MB/s eta 0:00:20\n",
      "   ------------------- -------------------- 148.7/300.9 MB 7.9 MB/s eta 0:00:20\n",
      "   ------------------- -------------------- 149.2/300.9 MB 8.1 MB/s eta 0:00:19\n",
      "   ------------------- -------------------- 149.7/300.9 MB 8.0 MB/s eta 0:00:19\n",
      "   ------------------- -------------------- 150.2/300.9 MB 8.2 MB/s eta 0:00:19\n",
      "   -------------------- ------------------- 150.7/300.9 MB 8.2 MB/s eta 0:00:19\n",
      "   -------------------- ------------------- 151.3/300.9 MB 8.3 MB/s eta 0:00:19\n",
      "   -------------------- ------------------- 151.7/300.9 MB 8.4 MB/s eta 0:00:18\n",
      "   -------------------- ------------------- 152.2/300.9 MB 8.5 MB/s eta 0:00:18\n",
      "   -------------------- ------------------- 152.6/300.9 MB 8.5 MB/s eta 0:00:18\n",
      "   -------------------- ------------------- 153.0/300.9 MB 8.4 MB/s eta 0:00:18\n",
      "   -------------------- ------------------- 153.5/300.9 MB 8.4 MB/s eta 0:00:18\n",
      "   -------------------- ------------------- 153.8/300.9 MB 8.4 MB/s eta 0:00:18\n",
      "   -------------------- ------------------- 154.1/300.9 MB 8.3 MB/s eta 0:00:18\n",
      "   -------------------- ------------------- 154.4/300.9 MB 8.3 MB/s eta 0:00:18\n",
      "   -------------------- ------------------- 154.8/300.9 MB 8.4 MB/s eta 0:00:18\n",
      "   -------------------- ------------------- 155.2/300.9 MB 8.4 MB/s eta 0:00:18\n",
      "   -------------------- ------------------- 155.5/300.9 MB 8.3 MB/s eta 0:00:18\n",
      "   -------------------- ------------------- 155.7/300.9 MB 8.3 MB/s eta 0:00:18\n",
      "   -------------------- ------------------- 155.9/300.9 MB 8.2 MB/s eta 0:00:18\n",
      "   -------------------- ------------------- 156.0/300.9 MB 7.8 MB/s eta 0:00:19\n",
      "   -------------------- ------------------- 156.2/300.9 MB 7.7 MB/s eta 0:00:19\n",
      "   -------------------- ------------------- 156.4/300.9 MB 7.5 MB/s eta 0:00:20\n",
      "   -------------------- ------------------- 156.7/300.9 MB 7.5 MB/s eta 0:00:20\n",
      "   -------------------- ------------------- 156.9/300.9 MB 7.4 MB/s eta 0:00:20\n",
      "   -------------------- ------------------- 157.2/300.9 MB 7.6 MB/s eta 0:00:19\n",
      "   -------------------- ------------------- 157.5/300.9 MB 7.7 MB/s eta 0:00:19\n",
      "   -------------------- ------------------- 157.8/300.9 MB 7.7 MB/s eta 0:00:19\n",
      "   --------------------- ------------------ 158.2/300.9 MB 7.7 MB/s eta 0:00:19\n",
      "   --------------------- ------------------ 158.6/300.9 MB 7.7 MB/s eta 0:00:19\n",
      "   --------------------- ------------------ 158.9/300.9 MB 7.7 MB/s eta 0:00:19\n",
      "   --------------------- ------------------ 159.3/300.9 MB 7.6 MB/s eta 0:00:19\n",
      "   --------------------- ------------------ 159.6/300.9 MB 7.4 MB/s eta 0:00:19\n",
      "   --------------------- ------------------ 159.8/300.9 MB 7.4 MB/s eta 0:00:20\n",
      "   --------------------- ------------------ 160.1/300.9 MB 7.2 MB/s eta 0:00:20\n",
      "   --------------------- ------------------ 160.3/300.9 MB 7.1 MB/s eta 0:00:20\n",
      "   --------------------- ------------------ 160.7/300.9 MB 7.0 MB/s eta 0:00:20\n",
      "   --------------------- ------------------ 161.0/300.9 MB 7.0 MB/s eta 0:00:21\n",
      "   --------------------- ------------------ 161.1/300.9 MB 6.8 MB/s eta 0:00:21\n",
      "   --------------------- ------------------ 161.5/300.9 MB 6.7 MB/s eta 0:00:21\n",
      "   --------------------- ------------------ 161.7/300.9 MB 6.6 MB/s eta 0:00:22\n",
      "   --------------------- ------------------ 161.9/300.9 MB 6.5 MB/s eta 0:00:22\n",
      "   --------------------- ------------------ 162.1/300.9 MB 6.4 MB/s eta 0:00:22\n",
      "   --------------------- ------------------ 162.3/300.9 MB 6.4 MB/s eta 0:00:22\n",
      "   --------------------- ------------------ 162.7/300.9 MB 6.4 MB/s eta 0:00:22\n",
      "   --------------------- ------------------ 163.0/300.9 MB 6.3 MB/s eta 0:00:22\n",
      "   --------------------- ------------------ 163.3/300.9 MB 6.2 MB/s eta 0:00:23\n",
      "   --------------------- ------------------ 163.7/300.9 MB 6.2 MB/s eta 0:00:23\n",
      "   --------------------- ------------------ 164.1/300.9 MB 6.2 MB/s eta 0:00:22\n",
      "   --------------------- ------------------ 164.5/300.9 MB 6.3 MB/s eta 0:00:22\n",
      "   --------------------- ------------------ 164.9/300.9 MB 6.3 MB/s eta 0:00:22\n",
      "   --------------------- ------------------ 165.3/300.9 MB 6.3 MB/s eta 0:00:22\n",
      "   ---------------------- ----------------- 165.6/300.9 MB 6.4 MB/s eta 0:00:22\n",
      "   ---------------------- ----------------- 166.2/300.9 MB 6.7 MB/s eta 0:00:21\n",
      "   ---------------------- ----------------- 166.5/300.9 MB 6.8 MB/s eta 0:00:20\n",
      "   ---------------------- ----------------- 167.0/300.9 MB 7.0 MB/s eta 0:00:20\n",
      "   ---------------------- ----------------- 167.2/300.9 MB 7.0 MB/s eta 0:00:20\n",
      "   ---------------------- ----------------- 167.5/300.9 MB 7.0 MB/s eta 0:00:20\n",
      "   ---------------------- ----------------- 167.8/300.9 MB 7.0 MB/s eta 0:00:20\n",
      "   ---------------------- ----------------- 168.2/300.9 MB 7.0 MB/s eta 0:00:19\n",
      "   ---------------------- ----------------- 168.6/300.9 MB 7.0 MB/s eta 0:00:19\n",
      "   ---------------------- ----------------- 169.0/300.9 MB 7.0 MB/s eta 0:00:19\n",
      "   ---------------------- ----------------- 169.5/300.9 MB 7.0 MB/s eta 0:00:19\n",
      "   ---------------------- ----------------- 169.7/300.9 MB 7.0 MB/s eta 0:00:19\n",
      "   ---------------------- ----------------- 170.1/300.9 MB 7.1 MB/s eta 0:00:19\n",
      "   ---------------------- ----------------- 170.4/300.9 MB 7.3 MB/s eta 0:00:18\n",
      "   ---------------------- ----------------- 170.8/300.9 MB 7.3 MB/s eta 0:00:18\n",
      "   ---------------------- ----------------- 171.2/300.9 MB 7.5 MB/s eta 0:00:18\n",
      "   ---------------------- ----------------- 171.7/300.9 MB 7.6 MB/s eta 0:00:17\n",
      "   ---------------------- ----------------- 172.1/300.9 MB 7.7 MB/s eta 0:00:17\n",
      "   ---------------------- ----------------- 172.6/300.9 MB 8.0 MB/s eta 0:00:17\n",
      "   ---------------------- ----------------- 173.0/300.9 MB 8.3 MB/s eta 0:00:16\n",
      "   ----------------------- ---------------- 173.4/300.9 MB 8.4 MB/s eta 0:00:16\n",
      "   ----------------------- ---------------- 173.8/300.9 MB 8.4 MB/s eta 0:00:16\n",
      "   ----------------------- ---------------- 174.2/300.9 MB 8.3 MB/s eta 0:00:16\n",
      "   ----------------------- ---------------- 174.5/300.9 MB 8.4 MB/s eta 0:00:16\n",
      "   ----------------------- ---------------- 174.9/300.9 MB 8.2 MB/s eta 0:00:16\n",
      "   ----------------------- ---------------- 175.3/300.9 MB 8.3 MB/s eta 0:00:16\n",
      "   ----------------------- ---------------- 175.7/300.9 MB 8.3 MB/s eta 0:00:16\n",
      "   ----------------------- ---------------- 176.1/300.9 MB 8.3 MB/s eta 0:00:16\n",
      "   ----------------------- ---------------- 176.5/300.9 MB 8.3 MB/s eta 0:00:16\n",
      "   ----------------------- ---------------- 176.8/300.9 MB 8.3 MB/s eta 0:00:15\n",
      "   ----------------------- ---------------- 177.2/300.9 MB 8.2 MB/s eta 0:00:16\n",
      "   ----------------------- ---------------- 177.4/300.9 MB 8.2 MB/s eta 0:00:16\n",
      "   ----------------------- ---------------- 177.9/300.9 MB 8.4 MB/s eta 0:00:15\n",
      "   ----------------------- ---------------- 178.1/300.9 MB 8.4 MB/s eta 0:00:15\n",
      "   ----------------------- ---------------- 178.4/300.9 MB 8.2 MB/s eta 0:00:15\n",
      "   ----------------------- ---------------- 178.8/300.9 MB 8.2 MB/s eta 0:00:15\n",
      "   ----------------------- ---------------- 179.2/300.9 MB 8.2 MB/s eta 0:00:15\n",
      "   ----------------------- ---------------- 179.7/300.9 MB 8.2 MB/s eta 0:00:15\n",
      "   ----------------------- ---------------- 180.1/300.9 MB 8.4 MB/s eta 0:00:15\n",
      "   ----------------------- ---------------- 180.5/300.9 MB 8.4 MB/s eta 0:00:15\n",
      "   ------------------------ --------------- 180.9/300.9 MB 8.3 MB/s eta 0:00:15\n",
      "   ------------------------ --------------- 181.3/300.9 MB 8.3 MB/s eta 0:00:15\n",
      "   ------------------------ --------------- 181.6/300.9 MB 8.3 MB/s eta 0:00:15\n",
      "   ------------------------ --------------- 182.0/300.9 MB 8.2 MB/s eta 0:00:15\n",
      "   ------------------------ --------------- 182.3/300.9 MB 8.1 MB/s eta 0:00:15\n",
      "   ------------------------ --------------- 182.7/300.9 MB 8.1 MB/s eta 0:00:15\n",
      "   ------------------------ --------------- 183.0/300.9 MB 8.0 MB/s eta 0:00:15\n",
      "   ------------------------ --------------- 183.1/300.9 MB 7.8 MB/s eta 0:00:16\n",
      "   ------------------------ --------------- 183.6/300.9 MB 7.8 MB/s eta 0:00:16\n",
      "   ------------------------ --------------- 184.0/300.9 MB 7.8 MB/s eta 0:00:15\n",
      "   ------------------------ --------------- 184.5/300.9 MB 7.9 MB/s eta 0:00:15\n",
      "   ------------------------ --------------- 184.9/300.9 MB 8.0 MB/s eta 0:00:15\n",
      "   ------------------------ --------------- 185.3/300.9 MB 8.0 MB/s eta 0:00:15\n",
      "   ------------------------ --------------- 185.7/300.9 MB 8.1 MB/s eta 0:00:15\n",
      "   ------------------------ --------------- 186.0/300.9 MB 7.9 MB/s eta 0:00:15\n",
      "   ------------------------ --------------- 186.4/300.9 MB 7.9 MB/s eta 0:00:15\n",
      "   ------------------------ --------------- 186.7/300.9 MB 7.8 MB/s eta 0:00:15\n",
      "   ------------------------ --------------- 186.9/300.9 MB 7.6 MB/s eta 0:00:15\n",
      "   ------------------------ --------------- 187.2/300.9 MB 7.6 MB/s eta 0:00:15\n",
      "   ------------------------ --------------- 187.3/300.9 MB 7.5 MB/s eta 0:00:16\n",
      "   ------------------------ --------------- 187.5/300.9 MB 7.4 MB/s eta 0:00:16\n",
      "   ------------------------ --------------- 187.8/300.9 MB 7.4 MB/s eta 0:00:16\n",
      "   ------------------------- -------------- 188.2/300.9 MB 7.4 MB/s eta 0:00:16\n",
      "   ------------------------- -------------- 188.6/300.9 MB 7.6 MB/s eta 0:00:15\n",
      "   ------------------------- -------------- 188.9/300.9 MB 7.5 MB/s eta 0:00:15\n",
      "   ------------------------- -------------- 189.2/300.9 MB 7.5 MB/s eta 0:00:15\n",
      "   ------------------------- -------------- 189.6/300.9 MB 7.4 MB/s eta 0:00:15\n",
      "   ------------------------- -------------- 190.0/300.9 MB 7.4 MB/s eta 0:00:15\n",
      "   ------------------------- -------------- 190.4/300.9 MB 7.4 MB/s eta 0:00:15\n",
      "   ------------------------- -------------- 190.9/300.9 MB 7.4 MB/s eta 0:00:15\n",
      "   ------------------------- -------------- 191.3/300.9 MB 7.4 MB/s eta 0:00:15\n",
      "   ------------------------- -------------- 191.7/300.9 MB 7.5 MB/s eta 0:00:15\n",
      "   ------------------------- -------------- 192.1/300.9 MB 7.5 MB/s eta 0:00:15\n",
      "   ------------------------- -------------- 192.5/300.9 MB 7.6 MB/s eta 0:00:15\n",
      "   ------------------------- -------------- 192.9/300.9 MB 7.6 MB/s eta 0:00:15\n",
      "   ------------------------- -------------- 193.3/300.9 MB 7.7 MB/s eta 0:00:14\n",
      "   ------------------------- -------------- 193.7/300.9 MB 7.8 MB/s eta 0:00:14\n",
      "   ------------------------- -------------- 194.1/300.9 MB 7.8 MB/s eta 0:00:14\n",
      "   ------------------------- -------------- 194.6/300.9 MB 7.8 MB/s eta 0:00:14\n",
      "   ------------------------- -------------- 194.7/300.9 MB 7.6 MB/s eta 0:00:14\n",
      "   ------------------------- -------------- 194.9/300.9 MB 7.4 MB/s eta 0:00:15\n",
      "   ------------------------- -------------- 195.1/300.9 MB 7.4 MB/s eta 0:00:15\n",
      "   ------------------------- -------------- 195.2/300.9 MB 7.1 MB/s eta 0:00:15\n",
      "   ------------------------- -------------- 195.3/300.9 MB 7.0 MB/s eta 0:00:16\n",
      "   -------------------------- ------------- 195.6/300.9 MB 6.9 MB/s eta 0:00:16\n",
      "   -------------------------- ------------- 196.1/300.9 MB 7.0 MB/s eta 0:00:15\n",
      "   -------------------------- ------------- 196.3/300.9 MB 6.9 MB/s eta 0:00:16\n",
      "   -------------------------- ------------- 196.5/300.9 MB 6.8 MB/s eta 0:00:16\n",
      "   -------------------------- ------------- 196.8/300.9 MB 6.8 MB/s eta 0:00:16\n",
      "   -------------------------- ------------- 197.3/300.9 MB 7.0 MB/s eta 0:00:15\n",
      "   -------------------------- ------------- 197.6/300.9 MB 7.2 MB/s eta 0:00:15\n",
      "   -------------------------- ------------- 198.1/300.9 MB 7.4 MB/s eta 0:00:14\n",
      "   -------------------------- ------------- 198.5/300.9 MB 7.4 MB/s eta 0:00:14\n",
      "   -------------------------- ------------- 199.0/300.9 MB 7.5 MB/s eta 0:00:14\n",
      "   -------------------------- ------------- 199.4/300.9 MB 7.4 MB/s eta 0:00:14\n",
      "   -------------------------- ------------- 199.8/300.9 MB 7.5 MB/s eta 0:00:14\n",
      "   -------------------------- ------------- 200.2/300.9 MB 7.6 MB/s eta 0:00:14\n",
      "   -------------------------- ------------- 200.6/300.9 MB 7.5 MB/s eta 0:00:14\n",
      "   -------------------------- ------------- 200.9/300.9 MB 7.5 MB/s eta 0:00:14\n",
      "   -------------------------- ------------- 200.9/300.9 MB 7.4 MB/s eta 0:00:14\n",
      "   -------------------------- ------------- 201.1/300.9 MB 7.1 MB/s eta 0:00:15\n",
      "   -------------------------- ------------- 201.3/300.9 MB 7.0 MB/s eta 0:00:15\n",
      "   -------------------------- ------------- 201.5/300.9 MB 6.9 MB/s eta 0:00:15\n",
      "   -------------------------- ------------- 201.9/300.9 MB 6.9 MB/s eta 0:00:15\n",
      "   -------------------------- ------------- 202.2/300.9 MB 6.8 MB/s eta 0:00:15\n",
      "   -------------------------- ------------- 202.6/300.9 MB 6.8 MB/s eta 0:00:15\n",
      "   -------------------------- ------------- 203.0/300.9 MB 6.8 MB/s eta 0:00:15\n",
      "   --------------------------- ------------ 203.3/300.9 MB 6.7 MB/s eta 0:00:15\n",
      "   --------------------------- ------------ 203.6/300.9 MB 6.7 MB/s eta 0:00:15\n",
      "   --------------------------- ------------ 204.0/300.9 MB 6.7 MB/s eta 0:00:15\n",
      "   --------------------------- ------------ 204.4/300.9 MB 6.7 MB/s eta 0:00:15\n",
      "   --------------------------- ------------ 204.8/300.9 MB 6.7 MB/s eta 0:00:15\n",
      "   --------------------------- ------------ 205.2/300.9 MB 7.0 MB/s eta 0:00:14\n",
      "   --------------------------- ------------ 205.5/300.9 MB 7.3 MB/s eta 0:00:14\n",
      "   --------------------------- ------------ 205.8/300.9 MB 7.4 MB/s eta 0:00:13\n",
      "   --------------------------- ------------ 206.2/300.9 MB 7.4 MB/s eta 0:00:13\n",
      "   --------------------------- ------------ 206.7/300.9 MB 7.4 MB/s eta 0:00:13\n",
      "   --------------------------- ------------ 207.1/300.9 MB 7.6 MB/s eta 0:00:13\n",
      "   --------------------------- ------------ 207.6/300.9 MB 7.6 MB/s eta 0:00:13\n",
      "   --------------------------- ------------ 207.9/300.9 MB 7.6 MB/s eta 0:00:13\n",
      "   --------------------------- ------------ 208.4/300.9 MB 7.6 MB/s eta 0:00:13\n",
      "   --------------------------- ------------ 208.9/300.9 MB 7.6 MB/s eta 0:00:13\n",
      "   --------------------------- ------------ 209.2/300.9 MB 7.6 MB/s eta 0:00:13\n",
      "   --------------------------- ------------ 209.5/300.9 MB 7.5 MB/s eta 0:00:13\n",
      "   --------------------------- ------------ 209.8/300.9 MB 7.4 MB/s eta 0:00:13\n",
      "   --------------------------- ------------ 210.2/300.9 MB 7.4 MB/s eta 0:00:13\n",
      "   ---------------------------- ----------- 210.7/300.9 MB 7.5 MB/s eta 0:00:12\n",
      "   ---------------------------- ----------- 211.1/300.9 MB 7.5 MB/s eta 0:00:12\n",
      "   ---------------------------- ----------- 211.5/300.9 MB 8.1 MB/s eta 0:00:12\n",
      "   ---------------------------- ----------- 212.0/300.9 MB 8.3 MB/s eta 0:00:11\n",
      "   ---------------------------- ----------- 212.4/300.9 MB 8.5 MB/s eta 0:00:11\n",
      "   ---------------------------- ----------- 212.8/300.9 MB 8.4 MB/s eta 0:00:11\n",
      "   ---------------------------- ----------- 213.1/300.9 MB 8.4 MB/s eta 0:00:11\n",
      "   ---------------------------- ----------- 213.5/300.9 MB 8.4 MB/s eta 0:00:11\n",
      "   ---------------------------- ----------- 214.0/300.9 MB 8.5 MB/s eta 0:00:11\n",
      "   ---------------------------- ----------- 214.4/300.9 MB 8.5 MB/s eta 0:00:11\n",
      "   ---------------------------- ----------- 214.8/300.9 MB 8.5 MB/s eta 0:00:11\n",
      "   ---------------------------- ----------- 215.2/300.9 MB 8.6 MB/s eta 0:00:10\n",
      "   ---------------------------- ----------- 215.7/300.9 MB 8.7 MB/s eta 0:00:10\n",
      "   ---------------------------- ----------- 216.0/300.9 MB 8.7 MB/s eta 0:00:10\n",
      "   ---------------------------- ----------- 216.4/300.9 MB 8.7 MB/s eta 0:00:10\n",
      "   ---------------------------- ----------- 216.8/300.9 MB 8.7 MB/s eta 0:00:10\n",
      "   ---------------------------- ----------- 217.3/300.9 MB 8.7 MB/s eta 0:00:10\n",
      "   ---------------------------- ----------- 217.6/300.9 MB 8.7 MB/s eta 0:00:10\n",
      "   ---------------------------- ----------- 218.0/300.9 MB 8.6 MB/s eta 0:00:10\n",
      "   ----------------------------- ---------- 218.4/300.9 MB 8.6 MB/s eta 0:00:10\n",
      "   ----------------------------- ---------- 218.8/300.9 MB 8.6 MB/s eta 0:00:10\n",
      "   ----------------------------- ---------- 219.2/300.9 MB 8.6 MB/s eta 0:00:10\n",
      "   ----------------------------- ---------- 219.7/300.9 MB 8.7 MB/s eta 0:00:10\n",
      "   ----------------------------- ---------- 220.1/300.9 MB 9.0 MB/s eta 0:00:10\n",
      "   ----------------------------- ---------- 220.6/300.9 MB 9.0 MB/s eta 0:00:09\n",
      "   ----------------------------- ---------- 221.1/300.9 MB 9.0 MB/s eta 0:00:09\n",
      "   ----------------------------- ---------- 221.5/300.9 MB 9.0 MB/s eta 0:00:09\n",
      "   ----------------------------- ---------- 222.0/300.9 MB 9.0 MB/s eta 0:00:09\n",
      "   ----------------------------- ---------- 222.4/300.9 MB 9.0 MB/s eta 0:00:09\n",
      "   ----------------------------- ---------- 222.9/300.9 MB 9.1 MB/s eta 0:00:09\n",
      "   ----------------------------- ---------- 223.3/300.9 MB 9.2 MB/s eta 0:00:09\n",
      "   ----------------------------- ---------- 223.8/300.9 MB 9.4 MB/s eta 0:00:09\n",
      "   ----------------------------- ---------- 224.3/300.9 MB 9.5 MB/s eta 0:00:09\n",
      "   ----------------------------- ---------- 224.7/300.9 MB 9.4 MB/s eta 0:00:09\n",
      "   ----------------------------- ---------- 225.1/300.9 MB 9.5 MB/s eta 0:00:08\n",
      "   ----------------------------- ---------- 225.6/300.9 MB 9.6 MB/s eta 0:00:08\n",
      "   ------------------------------ --------- 226.1/300.9 MB 9.6 MB/s eta 0:00:08\n",
      "   ------------------------------ --------- 226.6/300.9 MB 9.6 MB/s eta 0:00:08\n",
      "   ------------------------------ --------- 227.1/300.9 MB 9.8 MB/s eta 0:00:08\n",
      "   ------------------------------ --------- 227.5/300.9 MB 9.6 MB/s eta 0:00:08\n",
      "   ------------------------------ --------- 227.9/300.9 MB 9.8 MB/s eta 0:00:08\n",
      "   ------------------------------ --------- 228.4/300.9 MB 9.8 MB/s eta 0:00:08\n",
      "   ------------------------------ --------- 228.8/300.9 MB 9.8 MB/s eta 0:00:08\n",
      "   ------------------------------ --------- 229.3/300.9 MB 9.9 MB/s eta 0:00:08\n",
      "   ------------------------------ --------- 229.7/300.9 MB 9.9 MB/s eta 0:00:08\n",
      "   ------------------------------ --------- 230.2/300.9 MB 9.9 MB/s eta 0:00:08\n",
      "   ------------------------------ --------- 230.6/300.9 MB 9.9 MB/s eta 0:00:08\n",
      "   ------------------------------ --------- 231.1/300.9 MB 9.8 MB/s eta 0:00:08\n",
      "   ------------------------------ --------- 231.5/300.9 MB 9.8 MB/s eta 0:00:08\n",
      "   ------------------------------ --------- 232.0/300.9 MB 9.8 MB/s eta 0:00:08\n",
      "   ------------------------------ --------- 232.2/300.9 MB 9.8 MB/s eta 0:00:08\n",
      "   ------------------------------ --------- 232.4/300.9 MB 9.5 MB/s eta 0:00:08\n",
      "   ------------------------------ --------- 232.6/300.9 MB 9.2 MB/s eta 0:00:08\n",
      "   ------------------------------ --------- 232.9/300.9 MB 9.0 MB/s eta 0:00:08\n",
      "   ------------------------------ --------- 233.1/300.9 MB 8.8 MB/s eta 0:00:08\n",
      "   ------------------------------- -------- 233.4/300.9 MB 8.7 MB/s eta 0:00:08\n",
      "   ------------------------------- -------- 233.9/300.9 MB 8.7 MB/s eta 0:00:08\n",
      "   ------------------------------- -------- 234.3/300.9 MB 8.7 MB/s eta 0:00:08\n",
      "   ------------------------------- -------- 234.8/300.9 MB 8.7 MB/s eta 0:00:08\n",
      "   ------------------------------- -------- 235.2/300.9 MB 8.6 MB/s eta 0:00:08\n",
      "   ------------------------------- -------- 235.7/300.9 MB 8.7 MB/s eta 0:00:08\n",
      "   ------------------------------- -------- 236.0/300.9 MB 8.6 MB/s eta 0:00:08\n",
      "   ------------------------------- -------- 236.2/300.9 MB 8.5 MB/s eta 0:00:08\n",
      "   ------------------------------- -------- 236.5/300.9 MB 8.3 MB/s eta 0:00:08\n",
      "   ------------------------------- -------- 236.8/300.9 MB 8.2 MB/s eta 0:00:08\n",
      "   ------------------------------- -------- 237.0/300.9 MB 8.1 MB/s eta 0:00:08\n",
      "   ------------------------------- -------- 237.2/300.9 MB 7.9 MB/s eta 0:00:09\n",
      "   ------------------------------- -------- 237.3/300.9 MB 7.6 MB/s eta 0:00:09\n",
      "   ------------------------------- -------- 237.5/300.9 MB 7.5 MB/s eta 0:00:09\n",
      "   ------------------------------- -------- 237.8/300.9 MB 7.4 MB/s eta 0:00:09\n",
      "   ------------------------------- -------- 238.1/300.9 MB 7.4 MB/s eta 0:00:09\n",
      "   ------------------------------- -------- 238.5/300.9 MB 7.4 MB/s eta 0:00:09\n",
      "   ------------------------------- -------- 238.9/300.9 MB 7.3 MB/s eta 0:00:09\n",
      "   ------------------------------- -------- 239.1/300.9 MB 7.2 MB/s eta 0:00:09\n",
      "   ------------------------------- -------- 239.3/300.9 MB 7.0 MB/s eta 0:00:09\n",
      "   ------------------------------- -------- 239.5/300.9 MB 6.9 MB/s eta 0:00:09\n",
      "   ------------------------------- -------- 239.7/300.9 MB 6.8 MB/s eta 0:00:10\n",
      "   ------------------------------- -------- 239.9/300.9 MB 6.7 MB/s eta 0:00:10\n",
      "   ------------------------------- -------- 240.2/300.9 MB 6.6 MB/s eta 0:00:10\n",
      "   ------------------------------- -------- 240.4/300.9 MB 6.5 MB/s eta 0:00:10\n",
      "   ------------------------------- -------- 240.7/300.9 MB 6.4 MB/s eta 0:00:10\n",
      "   -------------------------------- ------- 241.0/300.9 MB 6.4 MB/s eta 0:00:10\n",
      "   -------------------------------- ------- 241.5/300.9 MB 6.4 MB/s eta 0:00:10\n",
      "   -------------------------------- ------- 241.8/300.9 MB 6.4 MB/s eta 0:00:10\n",
      "   -------------------------------- ------- 242.1/300.9 MB 6.2 MB/s eta 0:00:10\n",
      "   -------------------------------- ------- 242.4/300.9 MB 6.2 MB/s eta 0:00:10\n",
      "   -------------------------------- ------- 242.7/300.9 MB 6.3 MB/s eta 0:00:10\n",
      "   -------------------------------- ------- 242.9/300.9 MB 6.4 MB/s eta 0:00:10\n",
      "   -------------------------------- ------- 243.2/300.9 MB 6.4 MB/s eta 0:00:09\n",
      "   -------------------------------- ------- 243.7/300.9 MB 6.5 MB/s eta 0:00:09\n",
      "   -------------------------------- ------- 244.1/300.9 MB 6.5 MB/s eta 0:00:09\n",
      "   -------------------------------- ------- 244.6/300.9 MB 6.5 MB/s eta 0:00:09\n",
      "   -------------------------------- ------- 245.1/300.9 MB 6.5 MB/s eta 0:00:09\n",
      "   -------------------------------- ------- 245.6/300.9 MB 6.5 MB/s eta 0:00:09\n",
      "   -------------------------------- ------- 246.0/300.9 MB 6.5 MB/s eta 0:00:09\n",
      "   -------------------------------- ------- 246.6/300.9 MB 6.7 MB/s eta 0:00:09\n",
      "   -------------------------------- ------- 247.0/300.9 MB 6.9 MB/s eta 0:00:08\n",
      "   -------------------------------- ------- 247.5/300.9 MB 7.3 MB/s eta 0:00:08\n",
      "   -------------------------------- ------- 248.0/300.9 MB 7.6 MB/s eta 0:00:07\n",
      "   --------------------------------- ------ 248.4/300.9 MB 7.6 MB/s eta 0:00:07\n",
      "   --------------------------------- ------ 248.9/300.9 MB 7.6 MB/s eta 0:00:07\n",
      "   --------------------------------- ------ 249.4/300.9 MB 7.8 MB/s eta 0:00:07\n",
      "   --------------------------------- ------ 249.8/300.9 MB 8.4 MB/s eta 0:00:07\n",
      "   --------------------------------- ------ 250.3/300.9 MB 8.7 MB/s eta 0:00:06\n",
      "   --------------------------------- ------ 250.8/300.9 MB 9.0 MB/s eta 0:00:06\n",
      "   --------------------------------- ------ 251.2/300.9 MB 9.1 MB/s eta 0:00:06\n",
      "   --------------------------------- ------ 251.7/300.9 MB 9.1 MB/s eta 0:00:06\n",
      "   --------------------------------- ------ 252.2/300.9 MB 9.4 MB/s eta 0:00:06\n",
      "   --------------------------------- ------ 252.7/300.9 MB 9.6 MB/s eta 0:00:06\n",
      "   -------------------------------- ------ 253.2/300.9 MB 10.1 MB/s eta 0:00:05\n",
      "   -------------------------------- ------ 253.6/300.9 MB 10.1 MB/s eta 0:00:05\n",
      "   -------------------------------- ------ 254.1/300.9 MB 10.1 MB/s eta 0:00:05\n",
      "   -------------------------------- ------ 254.5/300.9 MB 10.1 MB/s eta 0:00:05\n",
      "   --------------------------------- ----- 255.0/300.9 MB 10.1 MB/s eta 0:00:05\n",
      "   --------------------------------- ----- 255.5/300.9 MB 10.2 MB/s eta 0:00:05\n",
      "   --------------------------------- ----- 256.0/300.9 MB 10.1 MB/s eta 0:00:05\n",
      "   --------------------------------- ----- 256.4/300.9 MB 10.1 MB/s eta 0:00:05\n",
      "   --------------------------------- ----- 256.9/300.9 MB 10.1 MB/s eta 0:00:05\n",
      "   --------------------------------- ----- 257.4/300.9 MB 10.1 MB/s eta 0:00:05\n",
      "   --------------------------------- ----- 257.8/300.9 MB 10.1 MB/s eta 0:00:05\n",
      "   --------------------------------- ----- 258.3/300.9 MB 10.1 MB/s eta 0:00:05\n",
      "   --------------------------------- ----- 258.7/300.9 MB 10.1 MB/s eta 0:00:05\n",
      "   ---------------------------------- ----- 259.2/300.9 MB 9.9 MB/s eta 0:00:05\n",
      "   ---------------------------------- ----- 259.5/300.9 MB 9.9 MB/s eta 0:00:05\n",
      "   ---------------------------------- ----- 260.0/300.9 MB 9.8 MB/s eta 0:00:05\n",
      "   ---------------------------------- ----- 260.4/300.9 MB 9.8 MB/s eta 0:00:05\n",
      "   ---------------------------------- ----- 260.8/300.9 MB 9.8 MB/s eta 0:00:05\n",
      "   ---------------------------------- ----- 261.3/300.9 MB 9.8 MB/s eta 0:00:05\n",
      "   ---------------------------------- ----- 261.5/300.9 MB 9.6 MB/s eta 0:00:05\n",
      "   ---------------------------------- ----- 261.6/300.9 MB 9.4 MB/s eta 0:00:05\n",
      "   ---------------------------------- ----- 261.8/300.9 MB 9.1 MB/s eta 0:00:05\n",
      "   ---------------------------------- ----- 261.9/300.9 MB 8.7 MB/s eta 0:00:05\n",
      "   ---------------------------------- ----- 262.0/300.9 MB 8.5 MB/s eta 0:00:05\n",
      "   ---------------------------------- ----- 262.2/300.9 MB 8.2 MB/s eta 0:00:05\n",
      "   ---------------------------------- ----- 262.3/300.9 MB 8.1 MB/s eta 0:00:05\n",
      "   ---------------------------------- ----- 262.5/300.9 MB 7.9 MB/s eta 0:00:05\n",
      "   ---------------------------------- ----- 262.7/300.9 MB 7.7 MB/s eta 0:00:05\n",
      "   ---------------------------------- ----- 263.2/300.9 MB 7.7 MB/s eta 0:00:05\n",
      "   ----------------------------------- ---- 263.6/300.9 MB 7.7 MB/s eta 0:00:05\n",
      "   ----------------------------------- ---- 264.0/300.9 MB 7.6 MB/s eta 0:00:05\n",
      "   ----------------------------------- ---- 264.4/300.9 MB 7.6 MB/s eta 0:00:05\n",
      "   ----------------------------------- ---- 264.9/300.9 MB 7.7 MB/s eta 0:00:05\n",
      "   ----------------------------------- ---- 265.3/300.9 MB 7.6 MB/s eta 0:00:05\n",
      "   ----------------------------------- ---- 265.7/300.9 MB 7.6 MB/s eta 0:00:05\n",
      "   ----------------------------------- ---- 266.1/300.9 MB 7.5 MB/s eta 0:00:05\n",
      "   ----------------------------------- ---- 266.5/300.9 MB 7.5 MB/s eta 0:00:05\n",
      "   ----------------------------------- ---- 267.0/300.9 MB 7.5 MB/s eta 0:00:05\n",
      "   ----------------------------------- ---- 267.4/300.9 MB 7.5 MB/s eta 0:00:05\n",
      "   ----------------------------------- ---- 267.9/300.9 MB 7.5 MB/s eta 0:00:05\n",
      "   ----------------------------------- ---- 268.3/300.9 MB 7.4 MB/s eta 0:00:05\n",
      "   ----------------------------------- ---- 268.8/300.9 MB 7.5 MB/s eta 0:00:05\n",
      "   ----------------------------------- ---- 269.2/300.9 MB 7.5 MB/s eta 0:00:05\n",
      "   ----------------------------------- ---- 269.6/300.9 MB 7.4 MB/s eta 0:00:05\n",
      "   ----------------------------------- ---- 270.0/300.9 MB 7.5 MB/s eta 0:00:05\n",
      "   ----------------------------------- ---- 270.5/300.9 MB 7.5 MB/s eta 0:00:05\n",
      "   ------------------------------------ --- 271.0/300.9 MB 7.5 MB/s eta 0:00:04\n",
      "   ------------------------------------ --- 271.3/300.9 MB 7.5 MB/s eta 0:00:04\n",
      "   ------------------------------------ --- 271.7/300.9 MB 7.5 MB/s eta 0:00:04\n",
      "   ------------------------------------ --- 272.1/300.9 MB 8.1 MB/s eta 0:00:04\n",
      "   ------------------------------------ --- 272.6/300.9 MB 8.8 MB/s eta 0:00:04\n",
      "   ------------------------------------ --- 273.0/300.9 MB 9.2 MB/s eta 0:00:04\n",
      "   ------------------------------------ --- 273.5/300.9 MB 9.2 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 273.8/300.9 MB 9.1 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 274.2/300.9 MB 9.2 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 274.6/300.9 MB 9.1 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 275.0/300.9 MB 9.1 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 275.4/300.9 MB 9.0 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 275.7/300.9 MB 9.0 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 276.0/300.9 MB 9.0 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 276.4/300.9 MB 8.8 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 276.7/300.9 MB 8.7 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 277.1/300.9 MB 8.7 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 277.5/300.9 MB 8.6 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 277.7/300.9 MB 8.6 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 278.0/300.9 MB 8.3 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 278.4/300.9 MB 8.3 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 278.8/300.9 MB 8.3 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 279.3/300.9 MB 8.3 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 279.8/300.9 MB 8.3 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 280.2/300.9 MB 8.3 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 280.6/300.9 MB 8.3 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 281.1/300.9 MB 8.3 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 281.5/300.9 MB 8.4 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 282.0/300.9 MB 8.4 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 282.3/300.9 MB 8.4 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 282.8/300.9 MB 8.4 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 283.3/300.9 MB 8.5 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 283.7/300.9 MB 8.4 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 284.2/300.9 MB 8.5 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 284.6/300.9 MB 8.5 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 285.2/300.9 MB 8.6 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 285.7/300.9 MB 8.8 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 286.3/300.9 MB 9.1 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 286.8/300.9 MB 9.4 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 287.4/300.9 MB 9.5 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 287.9/300.9 MB 9.8 MB/s eta 0:00:02\n",
      "   ------------------------------------- - 288.5/300.9 MB 10.2 MB/s eta 0:00:02\n",
      "   ------------------------------------- - 289.1/300.9 MB 10.4 MB/s eta 0:00:02\n",
      "   ------------------------------------- - 289.6/300.9 MB 10.4 MB/s eta 0:00:02\n",
      "   ------------------------------------- - 290.2/300.9 MB 10.6 MB/s eta 0:00:02\n",
      "   ------------------------------------- - 290.6/300.9 MB 10.6 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 290.9/300.9 MB 10.6 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 291.3/300.9 MB 10.6 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 291.6/300.9 MB 10.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 292.0/300.9 MB 10.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 292.5/300.9 MB 10.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 293.1/300.9 MB 10.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  293.7/300.9 MB 10.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  294.2/300.9 MB 10.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  294.7/300.9 MB 10.9 MB/s eta 0:00:01\n",
      "   --------------------------------------  295.3/300.9 MB 10.9 MB/s eta 0:00:01\n",
      "   --------------------------------------  295.9/300.9 MB 10.9 MB/s eta 0:00:01\n",
      "   --------------------------------------  296.4/300.9 MB 10.9 MB/s eta 0:00:01\n",
      "   --------------------------------------  297.0/300.9 MB 10.9 MB/s eta 0:00:01\n",
      "   --------------------------------------  297.6/300.9 MB 11.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  298.1/300.9 MB 10.9 MB/s eta 0:00:01\n",
      "   --------------------------------------  298.7/300.9 MB 11.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  299.2/300.9 MB 10.9 MB/s eta 0:00:01\n",
      "   --------------------------------------  299.8/300.9 MB 11.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  300.4/300.9 MB 11.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  300.9/300.9 MB 11.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  300.9/300.9 MB 11.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  300.9/300.9 MB 11.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  300.9/300.9 MB 11.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  300.9/300.9 MB 11.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  300.9/300.9 MB 11.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  300.9/300.9 MB 11.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  300.9/300.9 MB 11.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  300.9/300.9 MB 11.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  300.9/300.9 MB 11.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  300.9/300.9 MB 11.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  300.9/300.9 MB 11.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  300.9/300.9 MB 11.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  300.9/300.9 MB 11.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  300.9/300.9 MB 11.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  300.9/300.9 MB 11.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  300.9/300.9 MB 11.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  300.9/300.9 MB 11.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  300.9/300.9 MB 11.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  300.9/300.9 MB 11.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  300.9/300.9 MB 11.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  300.9/300.9 MB 11.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  300.9/300.9 MB 11.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  300.9/300.9 MB 11.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  300.9/300.9 MB 11.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  300.9/300.9 MB 11.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  300.9/300.9 MB 11.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  300.9/300.9 MB 11.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  300.9/300.9 MB 11.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  300.9/300.9 MB 11.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  300.9/300.9 MB 11.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 300.9/300.9 MB 3.7 MB/s eta 0:00:00\n",
      "Downloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "   ---------------------------------------- 0.0/133.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 133.7/133.7 kB 7.7 MB/s eta 0:00:00\n",
      "Downloading flatbuffers-23.5.26-py2.py3-none-any.whl (26 kB)\n",
      "Downloading grpcio-1.60.1-cp311-cp311-win_amd64.whl (3.7 MB)\n",
      "   ---------------------------------------- 0.0/3.7 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.3/3.7 MB 8.3 MB/s eta 0:00:01\n",
      "   --- ------------------------------------ 0.3/3.7 MB 4.1 MB/s eta 0:00:01\n",
      "   ------- -------------------------------- 0.7/3.7 MB 5.4 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 1.3/3.7 MB 7.3 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 1.8/3.7 MB 8.3 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 2.4/3.7 MB 9.0 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 2.8/3.7 MB 9.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 3.3/3.7 MB 9.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  3.7/3.7 MB 9.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 3.7/3.7 MB 8.7 MB/s eta 0:00:00\n",
      "Downloading keras-2.15.0-py3-none-any.whl (1.7 MB)\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ----------- ---------------------------- 0.5/1.7 MB 10.7 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 1.0/1.7 MB 13.0 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 1.6/1.7 MB 11.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.7/1.7 MB 12.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.7/1.7 MB 8.4 MB/s eta 0:00:00\n",
      "Downloading libclang-16.0.6-py2.py3-none-win_amd64.whl (24.4 MB)\n",
      "   ---------------------------------------- 0.0/24.4 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.5/24.4 MB 10.7 MB/s eta 0:00:03\n",
      "   - -------------------------------------- 1.1/24.4 MB 11.5 MB/s eta 0:00:03\n",
      "   -- ------------------------------------- 1.6/24.4 MB 11.6 MB/s eta 0:00:02\n",
      "   --- ------------------------------------ 2.2/24.4 MB 11.7 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 2.7/24.4 MB 11.7 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 3.3/24.4 MB 11.6 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 3.9/24.4 MB 11.7 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 4.4/24.4 MB 11.7 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 4.9/24.4 MB 11.6 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 5.5/24.4 MB 11.7 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 6.1/24.4 MB 11.8 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 6.6/24.4 MB 11.7 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 7.1/24.4 MB 11.7 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 7.6/24.4 MB 11.6 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 8.0/24.4 MB 11.6 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 8.4/24.4 MB 11.5 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 8.9/24.4 MB 11.4 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 9.5/24.4 MB 11.2 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 10.0/24.4 MB 11.3 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 10.5/24.4 MB 11.1 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 10.6/24.4 MB 10.9 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 10.8/24.4 MB 10.6 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 11.0/24.4 MB 10.2 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 11.5/24.4 MB 10.1 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 12.0/24.4 MB 10.2 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 12.6/24.4 MB 10.2 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 12.9/24.4 MB 9.9 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 13.3/24.4 MB 9.8 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 13.7/24.4 MB 9.8 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 14.2/24.4 MB 9.6 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 14.6/24.4 MB 9.6 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 15.0/24.4 MB 9.5 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 15.4/24.4 MB 9.4 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 15.7/24.4 MB 9.2 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 16.0/24.4 MB 9.0 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 16.4/24.4 MB 8.8 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 16.9/24.4 MB 8.8 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 17.3/24.4 MB 8.8 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 17.8/24.4 MB 8.8 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 18.4/24.4 MB 9.0 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 18.9/24.4 MB 9.0 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 19.4/24.4 MB 9.0 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 19.8/24.4 MB 8.8 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 20.3/24.4 MB 8.8 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 20.8/24.4 MB 9.2 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 21.4/24.4 MB 9.8 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 22.0/24.4 MB 9.8 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 22.4/24.4 MB 9.6 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 22.8/24.4 MB 9.5 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 23.2/24.4 MB 9.6 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 23.8/24.4 MB 9.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.2/24.4 MB 9.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.4/24.4 MB 9.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.4/24.4 MB 9.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.4/24.4 MB 9.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.4/24.4 MB 9.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 24.4/24.4 MB 8.4 MB/s eta 0:00:00\n",
      "Downloading ml_dtypes-0.2.0-cp311-cp311-win_amd64.whl (938 kB)\n",
      "   ---------------------------------------- 0.0/938.7 kB ? eta -:--:--\n",
      "   ----------------- --------------------- 409.6/938.7 kB 12.5 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 849.9/938.7 kB 10.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 938.7/938.7 kB 8.4 MB/s eta 0:00:00\n",
      "Downloading tensorboard-2.15.1-py3-none-any.whl (5.5 MB)\n",
      "   ---------------------------------------- 0.0/5.5 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 0.4/5.5 MB 8.9 MB/s eta 0:00:01\n",
      "   ------ --------------------------------- 1.0/5.5 MB 10.0 MB/s eta 0:00:01\n",
      "   --------- ------------------------------ 1.3/5.5 MB 9.4 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 1.8/5.5 MB 9.7 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 2.3/5.5 MB 9.9 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 2.9/5.5 MB 10.2 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 3.4/5.5 MB 10.4 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 3.9/5.5 MB 10.3 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 4.4/5.5 MB 10.4 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 4.9/5.5 MB 10.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  5.4/5.5 MB 10.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  5.5/5.5 MB 10.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 5.5/5.5 MB 9.3 MB/s eta 0:00:00\n",
      "Downloading protobuf-4.23.4-cp310-abi3-win_amd64.whl (422 kB)\n",
      "   ---------------------------------------- 0.0/422.5 kB ? eta -:--:--\n",
      "   -------------------------------------- - 409.6/422.5 kB 8.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 422.5/422.5 kB 6.6 MB/s eta 0:00:00\n",
      "Downloading tensorflow_estimator-2.15.0-py2.py3-none-any.whl (441 kB)\n",
      "   ---------------------------------------- 0.0/442.0 kB ? eta -:--:--\n",
      "   ---------------------------------------  440.3/442.0 kB 9.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 442.0/442.0 kB 9.2 MB/s eta 0:00:00\n",
      "Downloading termcolor-2.4.0-py3-none-any.whl (7.7 kB)\n",
      "Downloading google_auth-2.27.0-py2.py3-none-any.whl (186 kB)\n",
      "   ---------------------------------------- 0.0/186.8 kB ? eta -:--:--\n",
      "   --------------------------------------- 186.8/186.8 kB 11.8 MB/s eta 0:00:00\n",
      "Downloading google_auth_oauthlib-1.2.0-py2.py3-none-any.whl (24 kB)\n",
      "Downloading tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Downloading cachetools-5.3.2-py3-none-any.whl (9.3 kB)\n",
      "Installing collected packages: libclang, flatbuffers, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard-data-server, rsa, protobuf, opt-einsum, oauthlib, ml-dtypes, keras, grpcio, google-pasta, gast, cachetools, astunparse, absl-py, requests-oauthlib, google-auth, google-auth-oauthlib, tensorboard, tensorflow-intel, tensorflow\n",
      "Successfully installed absl-py-2.1.0 astunparse-1.6.3 cachetools-5.3.2 flatbuffers-23.5.26 gast-0.5.4 google-auth-2.27.0 google-auth-oauthlib-1.2.0 google-pasta-0.2.0 grpcio-1.60.1 keras-2.15.0 libclang-16.0.6 ml-dtypes-0.2.0 oauthlib-3.2.2 opt-einsum-3.3.0 protobuf-4.23.4 requests-oauthlib-1.3.1 rsa-4.9 tensorboard-2.15.1 tensorboard-data-server-0.7.2 tensorflow-2.15.0 tensorflow-estimator-2.15.0 tensorflow-intel-2.15.0 tensorflow-io-gcs-filesystem-0.31.0 termcolor-2.4.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The scripts pyrsa-decrypt.exe, pyrsa-encrypt.exe, pyrsa-keygen.exe, pyrsa-priv2pub.exe, pyrsa-sign.exe and pyrsa-verify.exe are installed in 'C:\\Users\\dinak\\AppData\\Roaming\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script google-oauthlib-tool.exe is installed in 'C:\\Users\\dinak\\AppData\\Roaming\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script tensorboard.exe is installed in 'C:\\Users\\dinak\\AppData\\Roaming\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts estimator_ckpt_converter.exe, import_pb_to_tensorboard.exe, saved_model_cli.exe, tensorboard.exe, tf_upgrade_v2.exe, tflite_convert.exe, toco.exe and toco_from_protos.exe are installed in 'C:\\Users\\dinak\\AppData\\Roaming\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a42f40c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
